{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============imports===================\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Set, Optional, Any\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "\n",
    "import pycountry\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "from collections import defaultdict\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================args=====================\n",
    "# checkpoints = 'best'\n",
    "checkpoints = None\n",
    "drop_points = [600000]\n",
    "# checkpoints = ['50000', '100000', '150000', '200000']\n",
    "checkpoints = ['1000', '100000', '200000', '300000', '400000', '600000']\n",
    "# checkpoints = ['1000', '10000', '100000', '200000', '300000', '400000', '500000', '600000']\n",
    "random_baseline = False\n",
    "# embedding_size = 1024\n",
    "top_k = 50\n",
    "attributes = ['Gender', 'Number', 'POS']\n",
    "shapes = {'Gender':'^', 'Number':'o', 'POS':'s'}\n",
    "# attributes = ['Aspect', 'Case', 'Definiteness', 'Finiteness', 'Gender', 'Mood', 'Number',\\\n",
    "#              'Person', 'POS', 'Tense', 'Voice']\n",
    "language = None\n",
    "show_plot = False\n",
    "experiment_name = 'inter-layer-17'\n",
    "# layers = [1, 5, 9, 13, 17, 21, 25]\n",
    "layers = None\n",
    "model = 'bloom-560m'\n",
    "sns.set_theme()\n",
    "\n",
    "# cross-lingual eval result args\n",
    "output_file_path = 'xtreme/outputs-temp/udpos/'\n",
    "output_file_suffix = '-LR2e-5-epoch10-MaxLen128'\n",
    "langs = ['ar', 'eu', 'ca', 'zh', 'en', 'fr', 'hi', 'mr', 'pt', 'es', 'ta', 'ur', 'vi']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================functions====================\n",
    "def convert_language_code(treebank_name):\n",
    "    \"\"\" Converts treebank names to language codes. \"\"\"\n",
    "    lang_name = treebank_name[3:].split(\"-\")[0].replace(\"_\", \" \")\n",
    "    lang = pycountry.languages.get(name=lang_name)\n",
    "\n",
    "    if lang is not None:\n",
    "        return lang.alpha_3.lower()\n",
    "\n",
    "    return \"unk\"\n",
    "\n",
    "def compute_overlap(data_raw, top_k):\n",
    "    mark_count: Dict[str, int] = {}  # num of languages logging that attribute\n",
    "    results: Dict[str, Counter] = {}\n",
    "    for run_config, dims in data_raw:\n",
    "        if run_config[\"embedding\"] != embedding:\n",
    "            continue\n",
    "\n",
    "        # Increment mark counting\n",
    "        if run_config[\"attribute\"] not in mark_count:\n",
    "            mark_count[run_config[\"attribute\"]] = 0\n",
    "\n",
    "        mark_count[run_config[\"attribute\"]] += 1\n",
    "\n",
    "        # Increment actual counters\n",
    "        if run_config[\"attribute\"] not in results:\n",
    "            results[run_config[\"attribute\"]] = Counter()\n",
    "\n",
    "        results[run_config[\"attribute\"]].update(dims[:top_k])\n",
    "\n",
    "    return results, mark_count\n",
    "\n",
    "\n",
    "def compute_similarity_for_attribute(attribute, data_raw, top_k, language_order: Optional[List[str]] = None):\n",
    "    data_list: List[Tuple[str, Set[int]]] = []\n",
    "    for run_config, dims in data_raw:\n",
    "        if run_config[\"embedding\"] != embedding:\n",
    "            continue\n",
    "\n",
    "        if run_config[\"attribute\"] != attribute:\n",
    "            continue\n",
    "\n",
    "        data_list.append((run_config[\"language\"], set(dims[:top_k])))\n",
    "\n",
    "    if not language_order:\n",
    "        data_list = sorted(data_list, key=lambda x: x[0])\n",
    "        return [x[0] for x in data_list], compute_similarity(data_list)\n",
    "    else:\n",
    "        data_list_dict = {k: v for k, v in data_list}\n",
    "        data_list_sorted = []\n",
    "        for x in language_order:\n",
    "            if x in data_list_dict:\n",
    "                data_list_sorted.append((x, data_list_dict[x]))\n",
    "\n",
    "        data_list = data_list_sorted\n",
    "        return [x[0] for x in data_list], compute_similarity(data_list)\n",
    "\n",
    "\n",
    "def compute_similarity_for_language(language, data_raw, top_k):\n",
    "    data_list: List[Tuple[str, Set[int]]] = []\n",
    "    for run_config, dims in data_raw:\n",
    "        if run_config[\"embedding\"] != embedding:\n",
    "            continue\n",
    "\n",
    "        if run_config[\"language\"] != language:\n",
    "            continue\n",
    "\n",
    "        data_list.append((run_config[\"attribute\"], set(dims[:top_k])))\n",
    "\n",
    "    data_list = sorted(data_list, key=lambda x: x[0])\n",
    "\n",
    "    return [x[0] for x in data_list], compute_similarity(data_list)\n",
    "\n",
    "\n",
    "def compute_jaccard_index(set_a: Set[int], set_b: Set[int]) -> float:\n",
    "    return len(set_a & set_b) / len(set_a | set_b)\n",
    "\n",
    "\n",
    "def compute_overlap_coefficient(set_a: Set[int], set_b: Set[int]) -> float:\n",
    "    return len(set_a & set_b) / min(len(set_a), len(set_b))\n",
    "\n",
    "\n",
    "def compute_similarity(data_list: List[Tuple[str, Set[int]]]):\n",
    "    num_items = len(data_list)\n",
    "    similarity_array = np.zeros((num_items, num_items))\n",
    "    extra_data = {\n",
    "        \"overlap\": np.empty((num_items, num_items), dtype=list),\n",
    "        \"overlap_num\": np.zeros((num_items, num_items)),\n",
    "    }\n",
    "    for idx_a, (group_a, dim_set_a) in enumerate(data_list):\n",
    "        for idx_b, (group_b, dim_set_b) in enumerate(data_list):\n",
    "            similarity_array[idx_a, idx_b] = compute_overlap_coefficient(dim_set_a, dim_set_b)\n",
    "            extra_data[\"overlap\"][idx_a, idx_b] = sorted(list(set(dim_set_a & dim_set_b)))\n",
    "            extra_data[\"overlap_num\"][idx_a, idx_b] = len(dim_set_a & dim_set_b)\n",
    "\n",
    "    return similarity_array, extra_data\n",
    "\n",
    "\n",
    "def compute_pvalues(overlap_num_matrix: np.array, p_val_dict: Dict[int, float]) -> np.array:\n",
    "    return np.vectorize(lambda x: p_val_dict[int(x)])(overlap_num_matrix)\n",
    "\n",
    "\n",
    "def build_statistical_significance_matrix(p_values_matrix, alpha=0.05, method=\"bonferroni\", symmetry=False):\n",
    "    num_rows = p_values_matrix.shape[0]\n",
    "    num_hypotheses = int(num_rows * (num_rows + 1) / 2) - num_rows\n",
    "    num_hypotheses = num_hypotheses if num_hypotheses > 0 else 999\n",
    "    alpha_bonferroni = alpha / num_hypotheses\n",
    "\n",
    "    if method == \"bonferroni\":\n",
    "        mask = np.tril(np.ones_like(p_values_matrix, dtype=bool), k=-1)\n",
    "        significance_matrix = (p_values_matrix < alpha_bonferroni) * mask\n",
    "    elif method == \"holm-bonferroni\":\n",
    "        mask = np.triu(np.ones_like(p_values_matrix)) * 9999.0\n",
    "        p_values_matrix += mask\n",
    "        p_values_matrix_flat = p_values_matrix.reshape(-1)\n",
    "        sorting_indices = p_values_matrix_flat.argsort()\n",
    "        unsorting_indices = sorting_indices.argsort()\n",
    "\n",
    "        sorted_p_values = p_values_matrix_flat[sorting_indices][:num_hypotheses]\n",
    "        alpha_holm = np.arange(1.0, num_hypotheses + 1.0)[::-1] ** -1 * alpha\n",
    "\n",
    "        broke = False\n",
    "        for k, (pval, alph) in enumerate(zip(sorted_p_values.tolist(), alpha_holm.tolist())):\n",
    "            if pval > alph:\n",
    "                broke = True\n",
    "                break\n",
    "\n",
    "        if not broke:\n",
    "            # Needed in case we never accepted the null hypothesis\n",
    "            k += 1\n",
    "\n",
    "        # k will be equal to the first index where we do NOT reject the null hypothesis.\n",
    "        # So we can accept the alternative hypothesis on all indices less than k\n",
    "        # e.g., if k == 0, we always accept the null hypothesis. If k == num_hypothesis\n",
    "        # we always reject the null hypothesis.\n",
    "        rejected_null_sorted = [True if idx < k else False for idx in range(num_hypotheses)]\n",
    "\n",
    "        # Pad remaining list with rejections\n",
    "        rejected_null_sorted.extend([False] * (num_rows ** 2 - num_hypotheses))\n",
    "\n",
    "        # Reverse sort\n",
    "        significance_matrix = np.array(rejected_null_sorted)[unsorting_indices].reshape(num_rows, num_rows)\n",
    "\n",
    "    if symmetry:\n",
    "        # Mirror along diagonal\n",
    "        significance_matrix = significance_matrix | significance_matrix.T\n",
    "\n",
    "    return significance_matrix\n",
    "\n",
    "\n",
    "def build_annotations_list(annotation_matrix):\n",
    "    n = annotation_matrix.shape[0]\n",
    "    annotation_list = []\n",
    "    for x in range(n):\n",
    "        for y in range(n):\n",
    "            if not annotation_matrix[x][y]:\n",
    "                continue\n",
    "\n",
    "            if x == y:\n",
    "                continue\n",
    "\n",
    "            annotation_list.append(\n",
    "                dict(\n",
    "                    x=x / n, y=y / n,\n",
    "                    xref='paper',\n",
    "                    yref='paper',\n",
    "                    text=\"■\",\n",
    "                    showarrow=False,\n",
    "                    xanchor=\"left\",\n",
    "                    yanchor=\"bottom\",\n",
    "                    font=dict(color=\"rgb(236,136,106)\")\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return annotation_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa3ac5b7400>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "ValueError",
     "evalue": "markevery=[600000] is iterable but not a valid numpy fancy index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/lines.py:195\u001b[0m, in \u001b[0;36m_mark_every_path\u001b[0;34m(markevery, tpath, affine, ax)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m     \u001b[39mreturn\u001b[39;00m Path(verts[markevery], _slice_or_none(codes, markevery))\n\u001b[1;32m    196\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mIndexError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 600000 is out of bounds for axis 0 with size 6",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/IPython/core/formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    341\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    342\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(bytes_io, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    153\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/backend_bases.py:2342\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     renderer \u001b[39m=\u001b[39m _get_renderer(\n\u001b[1;32m   2337\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure,\n\u001b[1;32m   2338\u001b[0m         functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m   2339\u001b[0m             print_method, orientation\u001b[39m=\u001b[39morientation)\n\u001b[1;32m   2340\u001b[0m     )\n\u001b[1;32m   2341\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mgetattr\u001b[39m(renderer, \u001b[39m\"\u001b[39m\u001b[39m_draw_disabled\u001b[39m\u001b[39m\"\u001b[39m, nullcontext)():\n\u001b[0;32m-> 2342\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m   2344\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2345\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/figure.py:3175\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3174\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3175\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3176\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3178\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[1;32m   3179\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/axes/_base.py:3064\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[39mif\u001b[39;00m artists_rasterized:\n\u001b[1;32m   3062\u001b[0m     _draw_rasterized(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[0;32m-> 3064\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3065\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3067\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   3068\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/lines.py:843\u001b[0m, in \u001b[0;36mLine2D.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    841\u001b[0m markevery \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_markevery()\n\u001b[1;32m    842\u001b[0m \u001b[39mif\u001b[39;00m markevery \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 843\u001b[0m     subsampled \u001b[39m=\u001b[39m _mark_every_path(\n\u001b[1;32m    844\u001b[0m         markevery, tpath, affine, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes)\n\u001b[1;32m    845\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    846\u001b[0m     subsampled \u001b[39m=\u001b[39m tpath\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/lines.py:197\u001b[0m, in \u001b[0;36m_mark_every_path\u001b[0;34m(markevery, tpath, affine, ax)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[39mreturn\u001b[39;00m Path(verts[markevery], _slice_or_none(codes, markevery))\n\u001b[1;32m    196\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mIndexError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 197\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    198\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmarkevery=\u001b[39m\u001b[39m{\u001b[39;00mmarkevery\u001b[39m!r}\u001b[39;00m\u001b[39m is iterable but not a valid numpy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfancy index\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmarkevery=\u001b[39m\u001b[39m{\u001b[39;00mmarkevery\u001b[39m!r}\u001b[39;00m\u001b[39m is not a recognized value\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: markevery=[600000] is iterable but not a valid numpy fancy index"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 550x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ======================read f1 scores==============================\n",
    "f1_dict = pd.read_csv(f'csv_files/{model}_f1-score.csv', index_col=0).to_dict()\n",
    "\n",
    "avg_f1_dict = {}\n",
    "fig, ax1 = plt.subplots(figsize=(5.5, 5))\n",
    "plt.ioff()\n",
    "\n",
    "for ckpt, f1_scores in f1_dict.items():\n",
    "    if ckpt == 'best':\n",
    "        continue\n",
    "    avg_f1_dict[int(ckpt)] = sum(f1_scores.values())/len(f1_scores.values())*100\n",
    "\n",
    "# for ckpt in checkpoints:\n",
    "#     f1_dict = {}\n",
    "#     ckpt_affix = '-intermediate-global_step' + ckpt\n",
    "#     output_file_name = os.path.join(output_file_path, model + ckpt_affix + output_file_suffix, 'test_results.txt')\n",
    "#     with open(output_file_name, 'r') as f:\n",
    "#         while True:\n",
    "#             line = f.readline()\n",
    "#             if not line:\n",
    "#                 break\n",
    "#             if 'language' in line:\n",
    "#                 lang = line.split('=')[1].split('\\n')[0]\n",
    "#                 f1_score = float(f.readline().split(' = ')[1])\n",
    "#                 if lang in langs:\n",
    "#                     f1_dict[lang] = f1_score \n",
    "#         print(f1_dict)\n",
    "#         avg_f1_score = sum(f1_dict.values())/len(f1_dict.values()) * 100\n",
    "#         avg_f1_dict[int(ckpt)] = avg_f1_score\n",
    "\n",
    "# plotting\n",
    "ckpts, f1_scores = zip(*avg_f1_dict.items())\n",
    "ax1.set_xlabel('global steps')\n",
    "ax1.set_ylabel('F1 scores', color='r')\n",
    "# ax1.set_ylim(30, 50)\n",
    "ax1.tick_params(axis='y', labelcolor='r', grid_alpha=0.5)\n",
    "ax1.plot(ckpts, f1_scores, 'r-')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ======================read cos similarities==============================\n",
    "# fig, ax1 = plt.subplots(figsize=(5.5, 5))\n",
    "# plt.ioff()\n",
    "# for layer in ['last-layer', experiment_name]:\n",
    "\n",
    "#     cos_dict = pd.read_csv(f'csv_files/{model}_{layer}_cos-similarity.csv', index_col=0).to_dict()\n",
    "\n",
    "#     avg_cos_dict = {}\n",
    "#     code_cos_dict = {}    \n",
    "\n",
    "#     for ckpt, cos_similarity in cos_dict.items():\n",
    "#         if ckpt == 'best':\n",
    "#             continue\n",
    "#         code_cos_dict[int(ckpt)] = cos_similarity['code']\n",
    "#         del cos_similarity['code']\n",
    "#         avg_cos_dict[int(ckpt)] = sum(cos_similarity.values())/len(cos_similarity.values())\n",
    "\n",
    "#     # plotting\n",
    "#     ckpts, cos_similarities = zip(*avg_cos_dict.items())\n",
    "#     code_cos_similarities = code_cos_dict.values()\n",
    "#     ax1.set_xlabel('global steps')\n",
    "#     ax1.set_ylabel('Cosine Similarities')\n",
    "#     ax1.tick_params(axis='y', grid_alpha=0.5)\n",
    "#     if layer == 'last-layer':         \n",
    "#         ax1.plot(ckpts, cos_similarities, 'm-', label='nl-last-layer')\n",
    "#         ax1.plot(ckpts, code_cos_similarities, '-', color='olive', label='code-last-layer')\n",
    "#     else:\n",
    "#         ax1.plot(ckpts, cos_similarities, '-', color='brown', label='nl')\n",
    "#         ax1.plot(ckpts, code_cos_similarities, 'c-', label='code')        \n",
    "#     plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop over checkpoints\n",
      "8\n",
      "[[1.   0.08 0.02 0.1  0.02 0.04 0.08 0.08]\n",
      " [0.08 1.   0.2  0.06 0.04 0.1  0.14 0.04]\n",
      " [0.02 0.2  1.   0.02 0.04 0.14 0.16 0.06]\n",
      " [0.1  0.06 0.02 1.   0.04 0.04 0.04 0.  ]\n",
      " [0.02 0.04 0.04 0.04 1.   0.12 0.04 0.12]\n",
      " [0.04 0.1  0.14 0.04 0.12 1.   0.34 0.06]\n",
      " [0.08 0.14 0.16 0.04 0.04 0.34 1.   0.06]\n",
      " [0.08 0.04 0.06 0.   0.12 0.06 0.06 1.  ]]\n",
      "11\n",
      "[[1.   0.06 0.   0.04 0.04 0.06 0.04 0.06 0.02 0.1  0.02]\n",
      " [0.06 1.   0.18 0.06 0.32 0.   0.04 0.3  0.3  0.06 0.02]\n",
      " [0.   0.18 1.   0.06 0.16 0.02 0.04 0.04 0.1  0.08 0.04]\n",
      " [0.04 0.06 0.06 1.   0.08 0.   0.02 0.04 0.04 0.   0.1 ]\n",
      " [0.04 0.32 0.16 0.08 1.   0.   0.06 0.12 0.24 0.08 0.02]\n",
      " [0.06 0.   0.02 0.   0.   1.   0.06 0.06 0.06 0.06 0.08]\n",
      " [0.04 0.04 0.04 0.02 0.06 0.06 1.   0.02 0.06 0.06 0.12]\n",
      " [0.06 0.3  0.04 0.04 0.12 0.06 0.02 1.   0.28 0.06 0.06]\n",
      " [0.02 0.3  0.1  0.04 0.24 0.06 0.06 0.28 1.   0.02 0.  ]\n",
      " [0.1  0.06 0.08 0.   0.08 0.06 0.06 0.06 0.02 1.   0.02]\n",
      " [0.02 0.02 0.04 0.1  0.02 0.08 0.12 0.06 0.   0.02 1.  ]]\n",
      "13\n",
      "[[1.   0.08 0.06 0.06 0.04 0.04 0.04 0.02 0.02 0.02 0.1  0.08 0.02]\n",
      " [0.08 1.   0.04 0.14 0.2  0.   0.06 0.02 0.04 0.06 0.04 0.08 0.1 ]\n",
      " [0.06 0.04 1.   0.06 0.16 0.06 0.02 0.1  0.06 0.06 0.06 0.08 0.06]\n",
      " [0.06 0.14 0.06 1.   0.06 0.1  0.02 0.08 0.08 0.04 0.06 0.08 0.12]\n",
      " [0.04 0.2  0.16 0.06 1.   0.   0.   0.04 0.1  0.1  0.04 0.06 0.1 ]\n",
      " [0.04 0.   0.06 0.1  0.   1.   0.02 0.04 0.04 0.06 0.02 0.06 0.04]\n",
      " [0.04 0.06 0.02 0.02 0.   0.02 1.   0.   0.04 0.08 0.04 0.06 0.04]\n",
      " [0.02 0.02 0.1  0.08 0.04 0.04 0.   1.   0.08 0.06 0.06 0.06 0.12]\n",
      " [0.02 0.04 0.06 0.08 0.1  0.04 0.04 0.08 1.   0.12 0.1  0.08 0.1 ]\n",
      " [0.02 0.06 0.06 0.04 0.1  0.06 0.08 0.06 0.12 1.   0.08 0.04 0.06]\n",
      " [0.1  0.04 0.06 0.06 0.04 0.02 0.04 0.06 0.1  0.08 1.   0.06 0.06]\n",
      " [0.08 0.08 0.08 0.08 0.06 0.06 0.06 0.06 0.08 0.04 0.06 1.   0.1 ]\n",
      " [0.02 0.1  0.06 0.12 0.1  0.04 0.04 0.12 0.1  0.06 0.06 0.1  1.  ]]\n",
      "8\n",
      "[[1.   0.24 0.32 0.14 0.02 0.26 0.22 0.08]\n",
      " [0.24 1.   0.36 0.06 0.02 0.26 0.3  0.04]\n",
      " [0.32 0.36 1.   0.1  0.08 0.3  0.3  0.04]\n",
      " [0.14 0.06 0.1  1.   0.08 0.14 0.1  0.12]\n",
      " [0.02 0.02 0.08 0.08 1.   0.04 0.08 0.04]\n",
      " [0.26 0.26 0.3  0.14 0.04 1.   0.46 0.08]\n",
      " [0.22 0.3  0.3  0.1  0.08 0.46 1.   0.04]\n",
      " [0.08 0.04 0.04 0.12 0.04 0.08 0.04 1.  ]]\n",
      "11\n",
      "[[1.   0.08 0.1  0.16 0.1  0.08 0.04 0.14 0.06 0.1  0.08]\n",
      " [0.08 1.   0.16 0.1  0.36 0.18 0.08 0.3  0.36 0.1  0.14]\n",
      " [0.1  0.16 1.   0.12 0.26 0.16 0.08 0.14 0.2  0.1  0.16]\n",
      " [0.16 0.1  0.12 1.   0.1  0.12 0.08 0.14 0.06 0.12 0.22]\n",
      " [0.1  0.36 0.26 0.1  1.   0.18 0.02 0.32 0.34 0.08 0.18]\n",
      " [0.08 0.18 0.16 0.12 0.18 1.   0.08 0.26 0.18 0.12 0.18]\n",
      " [0.04 0.08 0.08 0.08 0.02 0.08 1.   0.04 0.06 0.04 0.08]\n",
      " [0.14 0.3  0.14 0.14 0.32 0.26 0.04 1.   0.4  0.1  0.14]\n",
      " [0.06 0.36 0.2  0.06 0.34 0.18 0.06 0.4  1.   0.1  0.06]\n",
      " [0.1  0.1  0.1  0.12 0.08 0.12 0.04 0.1  0.1  1.   0.18]\n",
      " [0.08 0.14 0.16 0.22 0.18 0.18 0.08 0.14 0.06 0.18 1.  ]]\n",
      "13\n",
      "[[1.   0.1  0.08 0.02 0.1  0.06 0.04 0.12 0.12 0.06 0.12 0.08 0.14]\n",
      " [0.1  1.   0.1  0.08 0.14 0.04 0.02 0.18 0.18 0.04 0.08 0.06 0.08]\n",
      " [0.08 0.1  1.   0.06 0.18 0.06 0.02 0.14 0.2  0.06 0.06 0.1  0.1 ]\n",
      " [0.02 0.08 0.06 1.   0.18 0.08 0.08 0.1  0.12 0.06 0.08 0.04 0.1 ]\n",
      " [0.1  0.14 0.18 0.18 1.   0.12 0.02 0.26 0.22 0.12 0.06 0.14 0.18]\n",
      " [0.06 0.04 0.06 0.08 0.12 1.   0.06 0.08 0.06 0.04 0.08 0.06 0.12]\n",
      " [0.04 0.02 0.02 0.08 0.02 0.06 1.   0.04 0.02 0.08 0.08 0.04 0.  ]\n",
      " [0.12 0.18 0.14 0.1  0.26 0.08 0.04 1.   0.28 0.06 0.02 0.16 0.14]\n",
      " [0.12 0.18 0.2  0.12 0.22 0.06 0.02 0.28 1.   0.04 0.02 0.08 0.18]\n",
      " [0.06 0.04 0.06 0.06 0.12 0.04 0.08 0.06 0.04 1.   0.1  0.06 0.08]\n",
      " [0.12 0.08 0.06 0.08 0.06 0.08 0.08 0.02 0.02 0.1  1.   0.04 0.14]\n",
      " [0.08 0.06 0.1  0.04 0.14 0.06 0.04 0.16 0.08 0.06 0.04 1.   0.06]\n",
      " [0.14 0.08 0.1  0.1  0.18 0.12 0.   0.14 0.18 0.08 0.14 0.06 1.  ]]\n",
      "8\n",
      "[[1.   0.2  0.28 0.14 0.08 0.26 0.24 0.04]\n",
      " [0.2  1.   0.32 0.12 0.06 0.3  0.3  0.1 ]\n",
      " [0.28 0.32 1.   0.22 0.08 0.36 0.42 0.08]\n",
      " [0.14 0.12 0.22 1.   0.08 0.24 0.22 0.12]\n",
      " [0.08 0.06 0.08 0.08 1.   0.04 0.08 0.06]\n",
      " [0.26 0.3  0.36 0.24 0.04 1.   0.44 0.  ]\n",
      " [0.24 0.3  0.42 0.22 0.08 0.44 1.   0.06]\n",
      " [0.04 0.1  0.08 0.12 0.06 0.   0.06 1.  ]]\n",
      "11\n",
      "[[1.   0.12 0.18 0.08 0.12 0.16 0.02 0.1  0.12 0.1  0.14]\n",
      " [0.12 1.   0.16 0.2  0.34 0.18 0.   0.24 0.3  0.14 0.22]\n",
      " [0.18 0.16 1.   0.08 0.18 0.12 0.04 0.12 0.16 0.1  0.12]\n",
      " [0.08 0.2  0.08 1.   0.1  0.16 0.06 0.14 0.14 0.16 0.14]\n",
      " [0.12 0.34 0.18 0.1  1.   0.2  0.02 0.34 0.32 0.2  0.14]\n",
      " [0.16 0.18 0.12 0.16 0.2  1.   0.08 0.28 0.16 0.12 0.24]\n",
      " [0.02 0.   0.04 0.06 0.02 0.08 1.   0.02 0.02 0.1  0.04]\n",
      " [0.1  0.24 0.12 0.14 0.34 0.28 0.02 1.   0.34 0.1  0.16]\n",
      " [0.12 0.3  0.16 0.14 0.32 0.16 0.02 0.34 1.   0.14 0.12]\n",
      " [0.1  0.14 0.1  0.16 0.2  0.12 0.1  0.1  0.14 1.   0.1 ]\n",
      " [0.14 0.22 0.12 0.14 0.14 0.24 0.04 0.16 0.12 0.1  1.  ]]\n",
      "13\n",
      "[[1.   0.06 0.1  0.1  0.14 0.12 0.08 0.12 0.2  0.04 0.08 0.08 0.12]\n",
      " [0.06 1.   0.08 0.08 0.22 0.06 0.04 0.18 0.08 0.04 0.04 0.04 0.08]\n",
      " [0.1  0.08 1.   0.1  0.32 0.04 0.04 0.18 0.12 0.   0.06 0.22 0.18]\n",
      " [0.1  0.08 0.1  1.   0.06 0.   0.04 0.04 0.04 0.02 0.06 0.02 0.06]\n",
      " [0.14 0.22 0.32 0.06 1.   0.04 0.04 0.36 0.18 0.   0.1  0.12 0.2 ]\n",
      " [0.12 0.06 0.04 0.   0.04 1.   0.04 0.08 0.1  0.16 0.24 0.   0.06]\n",
      " [0.08 0.04 0.04 0.04 0.04 0.04 1.   0.04 0.06 0.02 0.08 0.06 0.08]\n",
      " [0.12 0.18 0.18 0.04 0.36 0.08 0.04 1.   0.16 0.   0.08 0.14 0.2 ]\n",
      " [0.2  0.08 0.12 0.04 0.18 0.1  0.06 0.16 1.   0.02 0.08 0.06 0.2 ]\n",
      " [0.04 0.04 0.   0.02 0.   0.16 0.02 0.   0.02 1.   0.1  0.04 0.02]\n",
      " [0.08 0.04 0.06 0.06 0.1  0.24 0.08 0.08 0.08 0.1  1.   0.06 0.18]\n",
      " [0.08 0.04 0.22 0.02 0.12 0.   0.06 0.14 0.06 0.04 0.06 1.   0.14]\n",
      " [0.12 0.08 0.18 0.06 0.2  0.06 0.08 0.2  0.2  0.02 0.18 0.14 1.  ]]\n",
      "8\n",
      "[[1.   0.2  0.24 0.18 0.12 0.22 0.2  0.1 ]\n",
      " [0.2  1.   0.4  0.2  0.12 0.28 0.4  0.06]\n",
      " [0.24 0.4  1.   0.38 0.08 0.38 0.48 0.04]\n",
      " [0.18 0.2  0.38 1.   0.16 0.3  0.28 0.06]\n",
      " [0.12 0.12 0.08 0.16 1.   0.14 0.12 0.1 ]\n",
      " [0.22 0.28 0.38 0.3  0.14 1.   0.46 0.1 ]\n",
      " [0.2  0.4  0.48 0.28 0.12 0.46 1.   0.04]\n",
      " [0.1  0.06 0.04 0.06 0.1  0.1  0.04 1.  ]]\n",
      "11\n",
      "[[1.   0.12 0.2  0.06 0.14 0.12 0.04 0.14 0.12 0.12 0.1 ]\n",
      " [0.12 1.   0.2  0.04 0.34 0.26 0.1  0.34 0.42 0.08 0.18]\n",
      " [0.2  0.2  1.   0.08 0.26 0.16 0.06 0.2  0.16 0.04 0.18]\n",
      " [0.06 0.04 0.08 1.   0.12 0.08 0.08 0.12 0.08 0.18 0.1 ]\n",
      " [0.14 0.34 0.26 0.12 1.   0.28 0.08 0.26 0.36 0.18 0.2 ]\n",
      " [0.12 0.26 0.16 0.08 0.28 1.   0.08 0.28 0.3  0.06 0.18]\n",
      " [0.04 0.1  0.06 0.08 0.08 0.08 1.   0.1  0.06 0.02 0.06]\n",
      " [0.14 0.34 0.2  0.12 0.26 0.28 0.1  1.   0.46 0.08 0.16]\n",
      " [0.12 0.42 0.16 0.08 0.36 0.3  0.06 0.46 1.   0.08 0.14]\n",
      " [0.12 0.08 0.04 0.18 0.18 0.06 0.02 0.08 0.08 1.   0.08]\n",
      " [0.1  0.18 0.18 0.1  0.2  0.18 0.06 0.16 0.14 0.08 1.  ]]\n",
      "13\n",
      "[[1.   0.1  0.18 0.06 0.12 0.14 0.08 0.18 0.16 0.1  0.08 0.14 0.14]\n",
      " [0.1  1.   0.16 0.04 0.22 0.06 0.04 0.28 0.16 0.02 0.02 0.04 0.14]\n",
      " [0.18 0.16 1.   0.06 0.24 0.1  0.06 0.2  0.12 0.04 0.06 0.1  0.14]\n",
      " [0.06 0.04 0.06 1.   0.06 0.02 0.02 0.06 0.04 0.04 0.06 0.08 0.08]\n",
      " [0.12 0.22 0.24 0.06 1.   0.1  0.06 0.26 0.2  0.06 0.04 0.12 0.14]\n",
      " [0.14 0.06 0.1  0.02 0.1  1.   0.12 0.2  0.12 0.12 0.16 0.04 0.16]\n",
      " [0.08 0.04 0.06 0.02 0.06 0.12 1.   0.08 0.08 0.08 0.1  0.14 0.04]\n",
      " [0.18 0.28 0.2  0.06 0.26 0.2  0.08 1.   0.22 0.1  0.1  0.1  0.12]\n",
      " [0.16 0.16 0.12 0.04 0.2  0.12 0.08 0.22 1.   0.1  0.08 0.14 0.1 ]\n",
      " [0.1  0.02 0.04 0.04 0.06 0.12 0.08 0.1  0.1  1.   0.08 0.1  0.06]\n",
      " [0.08 0.02 0.06 0.06 0.04 0.16 0.1  0.1  0.08 0.08 1.   0.04 0.1 ]\n",
      " [0.14 0.04 0.1  0.08 0.12 0.04 0.14 0.1  0.14 0.1  0.04 1.   0.16]\n",
      " [0.14 0.14 0.14 0.08 0.14 0.16 0.04 0.12 0.1  0.06 0.1  0.16 1.  ]]\n",
      "8\n",
      "[[1.   0.26 0.26 0.22 0.14 0.24 0.26 0.02]\n",
      " [0.26 1.   0.36 0.24 0.08 0.32 0.3  0.06]\n",
      " [0.26 0.36 1.   0.26 0.08 0.36 0.42 0.06]\n",
      " [0.22 0.24 0.26 1.   0.1  0.34 0.28 0.12]\n",
      " [0.14 0.08 0.08 0.1  1.   0.12 0.1  0.04]\n",
      " [0.24 0.32 0.36 0.34 0.12 1.   0.44 0.04]\n",
      " [0.26 0.3  0.42 0.28 0.1  0.44 1.   0.08]\n",
      " [0.02 0.06 0.06 0.12 0.04 0.04 0.08 1.  ]]\n",
      "11\n",
      "[[1.   0.18 0.18 0.12 0.18 0.14 0.02 0.14 0.16 0.12 0.14]\n",
      " [0.18 1.   0.3  0.2  0.34 0.22 0.06 0.38 0.4  0.22 0.2 ]\n",
      " [0.18 0.3  1.   0.2  0.24 0.22 0.06 0.28 0.24 0.08 0.08]\n",
      " [0.12 0.2  0.2  1.   0.18 0.12 0.04 0.12 0.12 0.14 0.12]\n",
      " [0.18 0.34 0.24 0.18 1.   0.2  0.04 0.28 0.3  0.18 0.14]\n",
      " [0.14 0.22 0.22 0.12 0.2  1.   0.12 0.12 0.2  0.18 0.24]\n",
      " [0.02 0.06 0.06 0.04 0.04 0.12 1.   0.04 0.06 0.06 0.04]\n",
      " [0.14 0.38 0.28 0.12 0.28 0.12 0.04 1.   0.42 0.08 0.1 ]\n",
      " [0.16 0.4  0.24 0.12 0.3  0.2  0.06 0.42 1.   0.1  0.14]\n",
      " [0.12 0.22 0.08 0.14 0.18 0.18 0.06 0.08 0.1  1.   0.08]\n",
      " [0.14 0.2  0.08 0.12 0.14 0.24 0.04 0.1  0.14 0.08 1.  ]]\n",
      "13\n",
      "[[1.   0.2  0.16 0.06 0.18 0.22 0.04 0.22 0.2  0.1  0.16 0.18 0.14]\n",
      " [0.2  1.   0.2  0.04 0.36 0.06 0.04 0.28 0.26 0.04 0.06 0.16 0.14]\n",
      " [0.16 0.2  1.   0.1  0.2  0.12 0.08 0.22 0.16 0.06 0.1  0.24 0.28]\n",
      " [0.06 0.04 0.1  1.   0.04 0.04 0.06 0.06 0.08 0.12 0.06 0.14 0.1 ]\n",
      " [0.18 0.36 0.2  0.04 1.   0.1  0.06 0.36 0.32 0.06 0.14 0.18 0.18]\n",
      " [0.22 0.06 0.12 0.04 0.1  1.   0.08 0.2  0.1  0.16 0.18 0.1  0.08]\n",
      " [0.04 0.04 0.08 0.06 0.06 0.08 1.   0.02 0.08 0.1  0.04 0.04 0.04]\n",
      " [0.22 0.28 0.22 0.06 0.36 0.2  0.02 1.   0.24 0.06 0.14 0.24 0.2 ]\n",
      " [0.2  0.26 0.16 0.08 0.32 0.1  0.08 0.24 1.   0.1  0.16 0.12 0.18]\n",
      " [0.1  0.04 0.06 0.12 0.06 0.16 0.1  0.06 0.1  1.   0.12 0.06 0.12]\n",
      " [0.16 0.06 0.1  0.06 0.14 0.18 0.04 0.14 0.16 0.12 1.   0.06 0.12]\n",
      " [0.18 0.16 0.24 0.14 0.18 0.1  0.04 0.24 0.12 0.06 0.06 1.   0.22]\n",
      " [0.14 0.14 0.28 0.1  0.18 0.08 0.04 0.2  0.18 0.12 0.12 0.22 1.  ]]\n",
      "8\n",
      "[[1.   0.06 0.06 0.   0.04 0.04 0.04 0.04]\n",
      " [0.06 1.   0.06 0.08 0.08 0.06 0.08 0.12]\n",
      " [0.06 0.06 1.   0.06 0.06 0.08 0.04 0.06]\n",
      " [0.   0.08 0.06 1.   0.04 0.04 0.1  0.06]\n",
      " [0.04 0.08 0.06 0.04 1.   0.04 0.04 0.08]\n",
      " [0.04 0.06 0.08 0.04 0.04 1.   0.1  0.06]\n",
      " [0.04 0.08 0.04 0.1  0.04 0.1  1.   0.02]\n",
      " [0.04 0.12 0.06 0.06 0.08 0.06 0.02 1.  ]]\n",
      "11\n",
      "[[1.   0.06 0.12 0.   0.06 0.04 0.08 0.04 0.02 0.   0.08]\n",
      " [0.06 1.   0.04 0.06 0.08 0.08 0.04 0.06 0.06 0.04 0.06]\n",
      " [0.12 0.04 1.   0.02 0.12 0.   0.06 0.1  0.06 0.04 0.08]\n",
      " [0.   0.06 0.02 1.   0.02 0.08 0.06 0.02 0.04 0.08 0.04]\n",
      " [0.06 0.08 0.12 0.02 1.   0.12 0.08 0.1  0.04 0.04 0.08]\n",
      " [0.04 0.08 0.   0.08 0.12 1.   0.08 0.06 0.04 0.06 0.04]\n",
      " [0.08 0.04 0.06 0.06 0.08 0.08 1.   0.   0.02 0.04 0.04]\n",
      " [0.04 0.06 0.1  0.02 0.1  0.06 0.   1.   0.02 0.1  0.04]\n",
      " [0.02 0.06 0.06 0.04 0.04 0.04 0.02 0.02 1.   0.   0.06]\n",
      " [0.   0.04 0.04 0.08 0.04 0.06 0.04 0.1  0.   1.   0.06]\n",
      " [0.08 0.06 0.08 0.04 0.08 0.04 0.04 0.04 0.06 0.06 1.  ]]\n",
      "13\n",
      "[[1.   0.04 0.06 0.02 0.04 0.08 0.   0.02 0.08 0.08 0.06 0.06 0.1 ]\n",
      " [0.04 1.   0.06 0.   0.04 0.06 0.06 0.06 0.08 0.06 0.04 0.06 0.04]\n",
      " [0.06 0.06 1.   0.04 0.06 0.06 0.02 0.14 0.06 0.12 0.   0.08 0.  ]\n",
      " [0.02 0.   0.04 1.   0.04 0.06 0.06 0.02 0.02 0.04 0.08 0.1  0.02]\n",
      " [0.04 0.04 0.06 0.04 1.   0.04 0.04 0.08 0.08 0.02 0.04 0.04 0.06]\n",
      " [0.08 0.06 0.06 0.06 0.04 1.   0.04 0.04 0.02 0.06 0.06 0.04 0.08]\n",
      " [0.   0.06 0.02 0.06 0.04 0.04 1.   0.08 0.08 0.02 0.04 0.04 0.06]\n",
      " [0.02 0.06 0.14 0.02 0.08 0.04 0.08 1.   0.06 0.06 0.06 0.02 0.04]\n",
      " [0.08 0.08 0.06 0.02 0.08 0.02 0.08 0.06 1.   0.04 0.04 0.   0.04]\n",
      " [0.08 0.06 0.12 0.04 0.02 0.06 0.02 0.06 0.04 1.   0.02 0.04 0.02]\n",
      " [0.06 0.04 0.   0.08 0.04 0.06 0.04 0.06 0.04 0.02 1.   0.04 0.02]\n",
      " [0.06 0.06 0.08 0.1  0.04 0.04 0.04 0.02 0.   0.04 0.04 1.   0.06]\n",
      " [0.1  0.04 0.   0.02 0.06 0.08 0.06 0.04 0.04 0.02 0.02 0.06 1.  ]]\n"
     ]
    }
   ],
   "source": [
    "# ===========================read overlap ratios============================\n",
    "# Dict{attr: Dict{checkpoint: avg_overlap_rate}}\n",
    "avg_overlap_rates: Dict[str, Dict[str, float]] = defaultdict(dict)\n",
    "    \n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "if layers is not None:\n",
    "    print(\"Loop over layers\")\n",
    "    for layer in layers:\n",
    "        embedding = model\n",
    "        experiment_name = f\"inter-layer-{layer}\"\n",
    "        if layer == 25:\n",
    "            experiment_name = \"last-layer\"\n",
    "        DEFAULT_RESULTS_FOLDER = f\"results/{embedding}/{experiment_name}\"\n",
    "\n",
    "        # print(listdir(DEFAULT_RESULTS_FOLDER))\n",
    "        RESULTS = []\n",
    "        rel_treebanks = []\n",
    "        for lang in listdir(DEFAULT_RESULTS_FOLDER):\n",
    "            if lang == 'UD_Chinese-CFL':\n",
    "                continue\n",
    "            rel_treebanks.append(lang)\n",
    "            for attr in listdir(join(DEFAULT_RESULTS_FOLDER, lang)):\n",
    "                RESULTS.append((lang, attr))\n",
    "                \n",
    "        # embedding, attribute, language\n",
    "\n",
    "        DEFAULT_FILE_FORMAT = join(DEFAULT_RESULTS_FOLDER, \"{lang}/{attribute}/loginfo.json\")\n",
    "\n",
    "        results_raw: List[Tuple[Dict[str, Any], List[int]]] = []\n",
    "\n",
    "        for l, a in RESULTS:  # noqa\n",
    "            if l in rel_treebanks:\n",
    "                with open(DEFAULT_FILE_FORMAT.format(lang=l, attribute=a), \"r\") as h:\n",
    "                    data = json.load(h)\n",
    "\n",
    "                results_raw.append(\n",
    "                    (\n",
    "                        { \"embedding\": embedding, \"attribute\": a,\n",
    "                        \"language\": convert_language_code(l) },\n",
    "                        [d[\"iteration_dimension\"] for d in data if \"iteration_dimension\" in d]\n",
    "                        if not random_baseline else random.sample(range(embedding_size), k=top_k)\n",
    "                    )\n",
    "            )\n",
    "        # Compute p values\n",
    "        num_permutations = 1000000\n",
    "        p_vals_cache_file = f\"{embedding}_{top_k}_{num_permutations}_pvals.pkl\"\n",
    "        if not os.path.exists(p_vals_cache_file):\n",
    "            # Compute p-values for different similarities\n",
    "            # if embedding in [\"bert-base-multilingual-cased\", \"xlm-roberta-base\"]:\n",
    "            #     dimensionality = 768\n",
    "            # elif embedding == \"xlm-roberta-large\":\n",
    "            #     dimensionality = 1024\n",
    "            # elif 'bloom' in embedding:\n",
    "            #     dimensionality = 1024\n",
    "            # else:\n",
    "            #     raise Exception(\"Embedding does not exist\")\n",
    "            #     dimensionality = 300\n",
    "            dimensionality = embedding_size\n",
    "\n",
    "            reference_order = random.sample(list(range(dimensionality)), dimensionality)\n",
    "            reference_top_k = reference_order[:top_k]\n",
    "            similarities = []\n",
    "\n",
    "            for i in tqdm(range(num_permutations)):\n",
    "                permuted_top_k = random.sample(reference_order, top_k)\n",
    "                similarities.append(compute_overlap_coefficient(set(reference_top_k), set(permuted_top_k)))\n",
    "                pvals = {}\n",
    "\n",
    "            for i in range(top_k + 1):\n",
    "                observed_hypothesis = i / top_k  # What is overlap score greater than or equal to?\n",
    "                permutations_match = [s for s in similarities if s >= observed_hypothesis]\n",
    "                pval = len(permutations_match) / num_permutations\n",
    "                print(f\"P-value when sim >= {observed_hypothesis} (overlap >= {i} dims): {pval:.5f}\")\n",
    "                pvals[i] = pval\n",
    "\n",
    "            with open(p_vals_cache_file, \"wb\") as h:\n",
    "                pickle.dump(pvals, h)\n",
    "        else:\n",
    "            with open(p_vals_cache_file, \"rb\") as h:\n",
    "                pvals = pickle.load(h)\n",
    "\n",
    "        for attr in attributes:\n",
    "            labels, (similarity_matrix, extra_data) = compute_similarity_for_attribute(\n",
    "                attr, results_raw, top_k)\n",
    "            \n",
    "            # get the average pairwise overlap:\n",
    "            print(len(labels))\n",
    "            print(similarity_matrix)\n",
    "            avg_overlap_rates[attr][layer] = np.average(similarity_matrix[np.triu_indices(len(labels), k = 1)])\n",
    "            \n",
    "\n",
    "            x_labels = labels\n",
    "            y_labels = labels\n",
    "\n",
    "            p_values_matrix = compute_pvalues(extra_data[\"overlap_num\"], pvals)\n",
    "            annotation_matrix = build_statistical_significance_matrix(\n",
    "                p_values_matrix, alpha=0.05, method=\"holm-bonferroni\", symmetry=True)\n",
    "    \n",
    "    for attr, overlap_rates in avg_overlap_rates.items():\n",
    "        overlap_rates = sorted(overlap_rates.items()) \n",
    "        print(overlap_rates)\n",
    "        x, y = zip(*overlap_rates)\n",
    "        \n",
    "        plt.plot(x, y, f'o-', label=attr)\n",
    "\n",
    "\n",
    "elif checkpoints is not None:\n",
    "    print(\"Loop over checkpoints\")\n",
    "    for checkpoint in checkpoints:\n",
    "        embedding = f\"{model}-intermediate-global_step{checkpoint}\"\n",
    "        if checkpoint == 'best':\n",
    "            embedding = model\n",
    "        DEFAULT_RESULTS_FOLDER = f\"results/{embedding}/{experiment_name}\"\n",
    "\n",
    "        # print(listdir(DEFAULT_RESULTS_FOLDER))\n",
    "        RESULTS = []\n",
    "        rel_treebanks = []\n",
    "        for lang in listdir(DEFAULT_RESULTS_FOLDER):\n",
    "            if lang == 'UD_Chinese-CFL':\n",
    "                continue\n",
    "            rel_treebanks.append(lang)\n",
    "            for attr in listdir(join(DEFAULT_RESULTS_FOLDER, lang)):\n",
    "                RESULTS.append((lang, attr))\n",
    "                \n",
    "        # embedding, attribute, language\n",
    "\n",
    "        DEFAULT_FILE_FORMAT = join(DEFAULT_RESULTS_FOLDER, \"{lang}/{attribute}/loginfo.json\")\n",
    "\n",
    "        results_raw: List[Tuple[Dict[str, Any], List[int]]] = []\n",
    "\n",
    "        for l, a in RESULTS:  # noqa\n",
    "            if l in rel_treebanks:\n",
    "                with open(DEFAULT_FILE_FORMAT.format(lang=l, attribute=a), \"r\") as h:\n",
    "                    data = json.load(h)\n",
    "\n",
    "                results_raw.append(\n",
    "                    (\n",
    "                        { \"embedding\": embedding, \"attribute\": a,\n",
    "                        \"language\": convert_language_code(l) },\n",
    "                        [d[\"iteration_dimension\"] for d in data if \"iteration_dimension\" in d]\n",
    "                        if not random_baseline else random.sample(range(embedding_size), k=top_k)\n",
    "                    )\n",
    "            )\n",
    "        # Compute p values\n",
    "        num_permutations = 1000000\n",
    "        p_vals_cache_file = f\"{model}_{top_k}_{num_permutations}_pvals.pkl\"\n",
    "        if not os.path.exists(p_vals_cache_file):\n",
    "            # Compute p-values for different similarities\n",
    "            # if embedding in [\"bert-base-multilingual-cased\", \"xlm-roberta-base\"]:\n",
    "            #     dimensionality = 768\n",
    "            # elif embedding == \"xlm-roberta-large\":\n",
    "            #     dimensionality = 1024\n",
    "            # elif 'bloom' in embedding:\n",
    "            #     dimensionality = 1024\n",
    "            # else:\n",
    "            #     raise Exception(\"Embedding does not exist\")\n",
    "            #     dimensionality = 300\n",
    "            dimensionality = embedding_size\n",
    "\n",
    "            reference_order = random.sample(list(range(dimensionality)), dimensionality)\n",
    "            reference_top_k = reference_order[:top_k]\n",
    "            similarities = []\n",
    "\n",
    "            for i in tqdm(range(num_permutations)):\n",
    "                permuted_top_k = random.sample(reference_order, top_k)\n",
    "                similarities.append(compute_overlap_coefficient(set(reference_top_k), set(permuted_top_k)))\n",
    "                pvals = {}\n",
    "\n",
    "            for i in range(top_k + 1):\n",
    "                observed_hypothesis = i / top_k  # What is overlap score greater than or equal to?\n",
    "                permutations_match = [s for s in similarities if s >= observed_hypothesis]\n",
    "                pval = len(permutations_match) / num_permutations\n",
    "                print(f\"P-value when sim >= {observed_hypothesis} (overlap >= {i} dims): {pval:.5f}\")\n",
    "                pvals[i] = pval\n",
    "\n",
    "            with open(p_vals_cache_file, \"wb\") as h:\n",
    "                pickle.dump(pvals, h)\n",
    "        else:\n",
    "            with open(p_vals_cache_file, \"rb\") as h:\n",
    "                pvals = pickle.load(h)\n",
    "\n",
    "        for attr in attributes:\n",
    "            labels, (similarity_matrix, extra_data) = compute_similarity_for_attribute(\n",
    "                attr, results_raw, top_k)\n",
    "            \n",
    "            # get the average pairwise overlap:\n",
    "            print(len(labels))\n",
    "            print(similarity_matrix)\n",
    "            if checkpoint == 'best':\n",
    "                avg_overlap_rates[attr][checkpoint] = np.average(similarity_matrix[np.triu_indices(len(labels), k = 1)])\n",
    "            else:\n",
    "                avg_overlap_rates[attr][int(checkpoint)] = np.average(similarity_matrix[np.triu_indices(len(labels), k = 1)])\n",
    "\n",
    "            x_labels = labels\n",
    "            y_labels = labels\n",
    "\n",
    "            p_values_matrix = compute_pvalues(extra_data[\"overlap_num\"], pvals)\n",
    "            annotation_matrix = build_statistical_significance_matrix(\n",
    "                p_values_matrix, alpha=0.05, method=\"holm-bonferroni\", symmetry=True)\n",
    "    \n",
    "    for attr, overlap_rates in avg_overlap_rates.items():\n",
    "        \n",
    "        if 'best' in overlap_rates.keys():\n",
    "            rate_for_best_checkpoint = [overlap_rates['best']]*8\n",
    "            del overlap_rates['best']\n",
    "            # plt.plot(x, rate_for_best_checkpoint, f'-{color}', label=f'{model}-{attr}')\n",
    "            \n",
    "        overlap_rates = sorted(overlap_rates.items()) \n",
    "        x, y = zip(*overlap_rates)\n",
    "        \n",
    "        shape = shapes[attr]\n",
    "        \n",
    "        ax2.plot(x, y, f'{shape}--', label=attr)      \n",
    "    \n",
    "else: \n",
    "    print(\"no x axises. please check.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2.legend(loc='center right', bbox_to_anchor=(1.5,0.5))\n",
    "# ax1.legend(loc='center left', bbox_to_anchor=(-0.4,0.5))\n",
    "ax2.set_ylabel('overlap rates')\n",
    "# ax1.locator_params(nbins=5, axis='x')\n",
    "fig.gca().yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "# fig.gca().yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "# if layers is not None:\n",
    "#     fig.xlabel(\"layer\")\n",
    "    \n",
    "# # plt.style.use('seaborn-darkgrid')\n",
    "# fig.tight_layout()\n",
    "sns.set_theme()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "markevery=[600000] is iterable but not a valid numpy fancy index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/lines.py:195\u001b[0m, in \u001b[0;36m_mark_every_path\u001b[0;34m(markevery, tpath, affine, ax)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m     \u001b[39mreturn\u001b[39;00m Path(verts[markevery], _slice_or_none(codes, markevery))\n\u001b[1;32m    196\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mIndexError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 600000 is out of bounds for axis 0 with size 6",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/root/multilingual-typology-probing/scatter_plot.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bconnect.westb.seetacloud.com/root/multilingual-typology-probing/scatter_plot.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     plt\u001b[39m.\u001b[39msavefig(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexperiments/scatterplots/\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m/layers.pdf\u001b[39m\u001b[39m'\u001b[39m, bbox_inches\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bconnect.westb.seetacloud.com/root/multilingual-typology-probing/scatter_plot.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39melif\u001b[39;00m checkpoints \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bconnect.westb.seetacloud.com/root/multilingual-typology-probing/scatter_plot.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     plt\u001b[39m.\u001b[39;49msavefig(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mexperiments/scatterplots/\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel\u001b[39m}\u001b[39;49;00m\u001b[39m/checkpoints_\u001b[39;49m\u001b[39m{\u001b[39;49;00mexperiment_name\u001b[39m}\u001b[39;49;00m\u001b[39m_f1-score.pdf\u001b[39;49m\u001b[39m'\u001b[39;49m, bbox_inches\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtight\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/pyplot.py:1023\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[39m.\u001b[39msavefig)\n\u001b[1;32m   1021\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msavefig\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1022\u001b[0m     fig \u001b[39m=\u001b[39m gcf()\n\u001b[0;32m-> 1023\u001b[0m     res \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39;49msavefig(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1024\u001b[0m     fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mdraw_idle()  \u001b[39m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/figure.py:3378\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3374\u001b[0m     \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes:\n\u001b[1;32m   3375\u001b[0m         stack\u001b[39m.\u001b[39menter_context(\n\u001b[1;32m   3376\u001b[0m             ax\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39m_cm_set(facecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m, edgecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m-> 3378\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(fname, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/backend_bases.py:2342\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     renderer \u001b[39m=\u001b[39m _get_renderer(\n\u001b[1;32m   2337\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure,\n\u001b[1;32m   2338\u001b[0m         functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m   2339\u001b[0m             print_method, orientation\u001b[39m=\u001b[39morientation)\n\u001b[1;32m   2340\u001b[0m     )\n\u001b[1;32m   2341\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mgetattr\u001b[39m(renderer, \u001b[39m\"\u001b[39m\u001b[39m_draw_disabled\u001b[39m\u001b[39m\"\u001b[39m, nullcontext)():\n\u001b[0;32m-> 2342\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m   2344\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2345\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/figure.py:3175\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3174\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3175\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3176\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3178\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[1;32m   3179\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/axes/_base.py:3064\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[39mif\u001b[39;00m artists_rasterized:\n\u001b[1;32m   3062\u001b[0m     _draw_rasterized(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[0;32m-> 3064\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3065\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3067\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   3068\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/lines.py:843\u001b[0m, in \u001b[0;36mLine2D.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    841\u001b[0m markevery \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_markevery()\n\u001b[1;32m    842\u001b[0m \u001b[39mif\u001b[39;00m markevery \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 843\u001b[0m     subsampled \u001b[39m=\u001b[39m _mark_every_path(\n\u001b[1;32m    844\u001b[0m         markevery, tpath, affine, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes)\n\u001b[1;32m    845\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    846\u001b[0m     subsampled \u001b[39m=\u001b[39m tpath\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/matplotlib/lines.py:197\u001b[0m, in \u001b[0;36m_mark_every_path\u001b[0;34m(markevery, tpath, affine, ax)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[39mreturn\u001b[39;00m Path(verts[markevery], _slice_or_none(codes, markevery))\n\u001b[1;32m    196\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mIndexError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 197\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    198\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmarkevery=\u001b[39m\u001b[39m{\u001b[39;00mmarkevery\u001b[39m!r}\u001b[39;00m\u001b[39m is iterable but not a valid numpy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfancy index\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmarkevery=\u001b[39m\u001b[39m{\u001b[39;00mmarkevery\u001b[39m!r}\u001b[39;00m\u001b[39m is not a recognized value\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: markevery=[600000] is iterable but not a valid numpy fancy index"
     ]
    }
   ],
   "source": [
    "if layers is not None:\n",
    "    plt.xlabel(\"layer\")\n",
    "    plt.ylabel('neuron overlap rate')\n",
    "    plt.savefig(f'experiments/scatterplots/{model}/layers.pdf', bbox_inches='tight')\n",
    "elif checkpoints is not None:\n",
    "    plt.savefig(f'experiments/scatterplots/{model}/checkpoints_{experiment_name}_f1-score.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilingual-typology-probing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed44db9dbf3c575ec3ddf9da9744b6e2502eab3ed89ccbe6b1ade08a3a1a68bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
