now processing task id: 3
CORPUS: UD_Chinese
python preprocess_treebank.py UD_Chinese --experiment-name inter-layer-17 --treebanks-root /home/s2308470/multilingual-typology-probing/data/ud/ud-treebanks-v2.1 --bloom bloom-1b7 --checkpoint 10000 --inter-layer 17 --use-gpu
Embeddings root: embeddings
Using GPU
0it [00:00, ?it/s]29it [00:00, 279.48it/s]57it [00:00, 270.04it/s]86it [00:00, 277.79it/s]117it [00:00, 287.42it/s]150it [00:00, 297.70it/s]187it [00:00, 319.78it/s]222it [00:00, 328.42it/s]255it [00:00, 314.71it/s]290it [00:00, 321.99it/s]323it [00:01, 313.76it/s]355it [00:01, 314.88it/s]389it [00:01, 319.52it/s]422it [00:01, 309.52it/s]458it [00:01, 321.60it/s]492it [00:01, 323.89it/s]500it [00:01, 310.09it/s]
0it [00:00, ?it/s]23it [00:00, 221.83it/s]55it [00:00, 277.71it/s]88it [00:00, 299.32it/s]124it [00:00, 322.75it/s]158it [00:00, 327.67it/s]191it [00:00, 308.17it/s]223it [00:00, 303.80it/s]257it [00:00, 313.54it/s]301it [00:00, 350.56it/s]339it [00:01, 356.37it/s]375it [00:01, 234.15it/s]412it [00:01, 262.81it/s]444it [00:01, 268.04it/s]478it [00:01, 284.41it/s]510it [00:01, 284.23it/s]546it [00:01, 300.87it/s]581it [00:01, 310.28it/s]615it [00:02, 316.67it/s]648it [00:02, 318.31it/s]681it [00:02, 307.56it/s]713it [00:02, 303.39it/s]744it [00:02, 293.76it/s]775it [00:02, 295.73it/s]808it [00:02, 303.28it/s]842it [00:02, 310.82it/s]874it [00:02, 303.93it/s]907it [00:03, 310.93it/s]939it [00:03, 302.89it/s]975it [00:03, 318.74it/s]1009it [00:03, 324.15it/s]1043it [00:03, 324.49it/s]1076it [00:03, 319.50it/s]1110it [00:03, 324.48it/s]1143it [00:03, 314.52it/s]1176it [00:03, 316.95it/s]1210it [00:03, 322.69it/s]1243it [00:04, 312.70it/s]1276it [00:04, 316.28it/s]1308it [00:04, 317.12it/s]1342it [00:04, 322.34it/s]1375it [00:04, 312.03it/s]1407it [00:04, 312.97it/s]1439it [00:04, 293.73it/s]1471it [00:04, 297.77it/s]1501it [00:04, 290.88it/s]1531it [00:05, 291.69it/s]1566it [00:05, 307.73it/s]1600it [00:05, 315.82it/s]1632it [00:05, 305.97it/s]1666it [00:05, 315.60it/s]1701it [00:05, 325.55it/s]1734it [00:05, 315.05it/s]1766it [00:05, 299.67it/s]1797it [00:05, 298.51it/s]1828it [00:05, 295.94it/s]1862it [00:06, 307.58it/s]1897it [00:06, 319.28it/s]1932it [00:06, 326.12it/s]1969it [00:06, 336.67it/s]2005it [00:06, 340.95it/s]2040it [00:06, 335.15it/s]2074it [00:06, 331.72it/s]2108it [00:06, 313.20it/s]2140it [00:06, 314.15it/s]2172it [00:07, 310.93it/s]2207it [00:07, 318.92it/s]2239it [00:07, 308.22it/s]2270it [00:07, 296.66it/s]2301it [00:07, 296.35it/s]2335it [00:07, 306.82it/s]2366it [00:07, 302.90it/s]2397it [00:07, 300.69it/s]2431it [00:07, 311.07it/s]2470it [00:07, 331.83it/s]2504it [00:08, 330.59it/s]2538it [00:08, 325.33it/s]2574it [00:08, 333.62it/s]2608it [00:08, 200.65it/s]2641it [00:08, 226.41it/s]2674it [00:08, 248.61it/s]2704it [00:08, 259.36it/s]2734it [00:09, 269.07it/s]2770it [00:09, 291.17it/s]2803it [00:09, 300.61it/s]2838it [00:09, 313.80it/s]2871it [00:09, 317.40it/s]2906it [00:09, 326.12it/s]2943it [00:09, 338.89it/s]2978it [00:09, 334.64it/s]3015it [00:09, 344.31it/s]3050it [00:09, 340.68it/s]3085it [00:10, 329.05it/s]3119it [00:10, 319.65it/s]3153it [00:10, 324.77it/s]3186it [00:10, 322.38it/s]3222it [00:10, 332.83it/s]3256it [00:10, 326.32it/s]3289it [00:10, 308.89it/s]3323it [00:10, 316.94it/s]3356it [00:10, 319.21it/s]3392it [00:11, 328.54it/s]3425it [00:11, 328.82it/s]3459it [00:11, 330.42it/s]3496it [00:11, 340.67it/s]3531it [00:11, 322.38it/s]3564it [00:11, 305.80it/s]3595it [00:11, 306.20it/s]3627it [00:11, 307.82it/s]3658it [00:11, 308.07it/s]3691it [00:11, 311.02it/s]3724it [00:12, 316.09it/s]3756it [00:12, 307.36it/s]3788it [00:12, 308.18it/s]3820it [00:12, 311.58it/s]3853it [00:12, 313.42it/s]3887it [00:12, 320.58it/s]3920it [00:12, 314.65it/s]3955it [00:12, 324.00it/s]3990it [00:12, 328.81it/s]3997it [00:12, 308.67it/s]
0it [00:00, ?it/s]30it [00:00, 295.41it/s]64it [00:00, 314.40it/s]99it [00:00, 328.97it/s]135it [00:00, 338.27it/s]169it [00:00, 329.90it/s]203it [00:00, 326.43it/s]238it [00:00, 333.47it/s]274it [00:00, 340.91it/s]309it [00:00, 333.08it/s]343it [00:01, 328.80it/s]376it [00:01, 318.74it/s]409it [00:01, 320.97it/s]444it [00:01, 328.77it/s]478it [00:01, 329.76it/s]500it [00:01, 327.66it/s]
Skipped:
{'total_sents': 4997}

Total: 0
Using model bloom-1b7-intermediate-global_step10000...
Processing UD_Chinese...
Traceback (most recent call last):
  File "preprocess_treebank.py", line 374, in <module>
    model = BloomModel.from_pretrained(bloom_model, 
  File "/home/s2308470/miniconda3/envs/multilingual-typology-probing/lib/python3.8/site-packages/transformers/modeling_utils.py", line 1878, in to
    return super().to(*args, **kwargs)
  File "/home/s2308470/miniconda3/envs/multilingual-typology-probing/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1145, in to
    return self._apply(convert)
  File "/home/s2308470/miniconda3/envs/multilingual-typology-probing/lib/python3.8/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/s2308470/miniconda3/envs/multilingual-typology-probing/lib/python3.8/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/s2308470/miniconda3/envs/multilingual-typology-probing/lib/python3.8/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/home/s2308470/miniconda3/envs/multilingual-typology-probing/lib/python3.8/site-packages/torch/nn/modules/module.py", line 820, in _apply
    param_applied = fn(param)
  File "/home/s2308470/miniconda3/envs/multilingual-typology-probing/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 5.94 GiB total capacity; 5.79 GiB already allocated; 35.31 MiB free; 5.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
