{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============imports===================\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Set, Optional, Any\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "\n",
    "import pycountry\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "from collections import defaultdict\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================args=====================\n",
    "# checkpoints = 'best'\n",
    "# checkpoints = ['best', '1000', '10000', '50000', '100000', '150000', '200000', '250000', '300000']\n",
    "checkpoints = ['best', '1000', '10000', '100000', '200000', '300000', '400000', '500000', '600000']\n",
    "random_baseline = False\n",
    "embedding_size = 1536\n",
    "top_k = 50\n",
    "attributes = ['Gender', 'Number', 'POS']\n",
    "shapes = {'Gender':'^', 'Number':'o', 'POS':'s'}\n",
    "# attributes = ['Aspect', 'Case', 'Definiteness', 'Finiteness', 'Gender', 'Mood', 'Number',\\\n",
    "#              'Person', 'POS', 'Tense', 'Voice']\n",
    "language = None\n",
    "show_plot = False\n",
    "experiment_name = 'inter-layer-17'\n",
    "# layers = [1, 5, 9, 13, 17, 21, 25]\n",
    "layers = None\n",
    "model = 'bloom-560m'\n",
    "\n",
    "\n",
    "# cross-lingual eval result args\n",
    "output_file_path = 'xtreme/outputs-temp/udpos/'\n",
    "output_file_suffix = '-LR2e-5-epoch10-MaxLen128'\n",
    "langs = ['ar', 'eu', 'ca', 'zh', 'en', 'fr', 'hi', 'mr', 'pt', 'es', 'ta', 'ur', 'vi']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================functions====================\n",
    "def convert_language_code(treebank_name):\n",
    "    \"\"\" Converts treebank names to language codes. \"\"\"\n",
    "    lang_name = treebank_name[3:].split(\"-\")[0].replace(\"_\", \" \")\n",
    "    lang = pycountry.languages.get(name=lang_name)\n",
    "\n",
    "    if lang is not None:\n",
    "        return lang.alpha_3.lower()\n",
    "\n",
    "    return \"unk\"\n",
    "\n",
    "def compute_overlap(data_raw, top_k):\n",
    "    mark_count: Dict[str, int] = {}  # num of languages logging that attribute\n",
    "    results: Dict[str, Counter] = {}\n",
    "    for run_config, dims in data_raw:\n",
    "        if run_config[\"embedding\"] != embedding:\n",
    "            continue\n",
    "\n",
    "        # Increment mark counting\n",
    "        if run_config[\"attribute\"] not in mark_count:\n",
    "            mark_count[run_config[\"attribute\"]] = 0\n",
    "\n",
    "        mark_count[run_config[\"attribute\"]] += 1\n",
    "\n",
    "        # Increment actual counters\n",
    "        if run_config[\"attribute\"] not in results:\n",
    "            results[run_config[\"attribute\"]] = Counter()\n",
    "\n",
    "        results[run_config[\"attribute\"]].update(dims[:top_k])\n",
    "\n",
    "    return results, mark_count\n",
    "\n",
    "\n",
    "def compute_similarity_for_attribute(attribute, data_raw, top_k, language_order: Optional[List[str]] = None):\n",
    "    data_list: List[Tuple[str, Set[int]]] = []\n",
    "    for run_config, dims in data_raw:\n",
    "        if run_config[\"embedding\"] != embedding:\n",
    "            continue\n",
    "\n",
    "        if run_config[\"attribute\"] != attribute:\n",
    "            continue\n",
    "\n",
    "        data_list.append((run_config[\"language\"], set(dims[:top_k])))\n",
    "\n",
    "    if not language_order:\n",
    "        data_list = sorted(data_list, key=lambda x: x[0])\n",
    "        return [x[0] for x in data_list], compute_similarity(data_list)\n",
    "    else:\n",
    "        data_list_dict = {k: v for k, v in data_list}\n",
    "        data_list_sorted = []\n",
    "        for x in language_order:\n",
    "            if x in data_list_dict:\n",
    "                data_list_sorted.append((x, data_list_dict[x]))\n",
    "\n",
    "        data_list = data_list_sorted\n",
    "        return [x[0] for x in data_list], compute_similarity(data_list)\n",
    "\n",
    "\n",
    "def compute_similarity_for_language(language, data_raw, top_k):\n",
    "    data_list: List[Tuple[str, Set[int]]] = []\n",
    "    for run_config, dims in data_raw:\n",
    "        if run_config[\"embedding\"] != embedding:\n",
    "            continue\n",
    "\n",
    "        if run_config[\"language\"] != language:\n",
    "            continue\n",
    "\n",
    "        data_list.append((run_config[\"attribute\"], set(dims[:top_k])))\n",
    "\n",
    "    data_list = sorted(data_list, key=lambda x: x[0])\n",
    "\n",
    "    return [x[0] for x in data_list], compute_similarity(data_list)\n",
    "\n",
    "\n",
    "def compute_jaccard_index(set_a: Set[int], set_b: Set[int]) -> float:\n",
    "    return len(set_a & set_b) / len(set_a | set_b)\n",
    "\n",
    "\n",
    "def compute_overlap_coefficient(set_a: Set[int], set_b: Set[int]) -> float:\n",
    "    return len(set_a & set_b) / min(len(set_a), len(set_b))\n",
    "\n",
    "\n",
    "def compute_similarity(data_list: List[Tuple[str, Set[int]]]):\n",
    "    num_items = len(data_list)\n",
    "    similarity_array = np.zeros((num_items, num_items))\n",
    "    extra_data = {\n",
    "        \"overlap\": np.empty((num_items, num_items), dtype=list),\n",
    "        \"overlap_num\": np.zeros((num_items, num_items)),\n",
    "    }\n",
    "    for idx_a, (group_a, dim_set_a) in enumerate(data_list):\n",
    "        for idx_b, (group_b, dim_set_b) in enumerate(data_list):\n",
    "            similarity_array[idx_a, idx_b] = compute_overlap_coefficient(dim_set_a, dim_set_b)\n",
    "            extra_data[\"overlap\"][idx_a, idx_b] = sorted(list(set(dim_set_a & dim_set_b)))\n",
    "            extra_data[\"overlap_num\"][idx_a, idx_b] = len(dim_set_a & dim_set_b)\n",
    "\n",
    "    return similarity_array, extra_data\n",
    "\n",
    "\n",
    "def compute_pvalues(overlap_num_matrix: np.array, p_val_dict: Dict[int, float]) -> np.array:\n",
    "    return np.vectorize(lambda x: p_val_dict[int(x)])(overlap_num_matrix)\n",
    "\n",
    "\n",
    "def build_statistical_significance_matrix(p_values_matrix, alpha=0.05, method=\"bonferroni\", symmetry=False):\n",
    "    num_rows = p_values_matrix.shape[0]\n",
    "    num_hypotheses = int(num_rows * (num_rows + 1) / 2) - num_rows\n",
    "    num_hypotheses = num_hypotheses if num_hypotheses > 0 else 999\n",
    "    alpha_bonferroni = alpha / num_hypotheses\n",
    "\n",
    "    if method == \"bonferroni\":\n",
    "        mask = np.tril(np.ones_like(p_values_matrix, dtype=bool), k=-1)\n",
    "        significance_matrix = (p_values_matrix < alpha_bonferroni) * mask\n",
    "    elif method == \"holm-bonferroni\":\n",
    "        mask = np.triu(np.ones_like(p_values_matrix)) * 9999.0\n",
    "        p_values_matrix += mask\n",
    "        p_values_matrix_flat = p_values_matrix.reshape(-1)\n",
    "        sorting_indices = p_values_matrix_flat.argsort()\n",
    "        unsorting_indices = sorting_indices.argsort()\n",
    "\n",
    "        sorted_p_values = p_values_matrix_flat[sorting_indices][:num_hypotheses]\n",
    "        alpha_holm = np.arange(1.0, num_hypotheses + 1.0)[::-1] ** -1 * alpha\n",
    "\n",
    "        broke = False\n",
    "        for k, (pval, alph) in enumerate(zip(sorted_p_values.tolist(), alpha_holm.tolist())):\n",
    "            if pval > alph:\n",
    "                broke = True\n",
    "                break\n",
    "\n",
    "        if not broke:\n",
    "            # Needed in case we never accepted the null hypothesis\n",
    "            k += 1\n",
    "\n",
    "        # k will be equal to the first index where we do NOT reject the null hypothesis.\n",
    "        # So we can accept the alternative hypothesis on all indices less than k\n",
    "        # e.g., if k == 0, we always accept the null hypothesis. If k == num_hypothesis\n",
    "        # we always reject the null hypothesis.\n",
    "        rejected_null_sorted = [True if idx < k else False for idx in range(num_hypotheses)]\n",
    "\n",
    "        # Pad remaining list with rejections\n",
    "        rejected_null_sorted.extend([False] * (num_rows ** 2 - num_hypotheses))\n",
    "\n",
    "        # Reverse sort\n",
    "        significance_matrix = np.array(rejected_null_sorted)[unsorting_indices].reshape(num_rows, num_rows)\n",
    "\n",
    "    if symmetry:\n",
    "        # Mirror along diagonal\n",
    "        significance_matrix = significance_matrix | significance_matrix.T\n",
    "\n",
    "    return significance_matrix\n",
    "\n",
    "\n",
    "def build_annotations_list(annotation_matrix):\n",
    "    n = annotation_matrix.shape[0]\n",
    "    annotation_list = []\n",
    "    for x in range(n):\n",
    "        for y in range(n):\n",
    "            if not annotation_matrix[x][y]:\n",
    "                continue\n",
    "\n",
    "            if x == y:\n",
    "                continue\n",
    "\n",
    "            annotation_list.append(\n",
    "                dict(\n",
    "                    x=x / n, y=y / n,\n",
    "                    xref='paper',\n",
    "                    yref='paper',\n",
    "                    text=\"â– \",\n",
    "                    showarrow=False,\n",
    "                    xanchor=\"left\",\n",
    "                    yanchor=\"bottom\",\n",
    "                    font=dict(color=\"rgb(236,136,106)\")\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return annotation_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ar': 0.011429136877520224, 'en': 0.8394129660893703, 'es': 0.6897495822259495, 'eu': 0.3518200592172377, 'fr': 0.6930645258646707, 'hi': 0.328683483376415, 'mr': 0.2808988764044944, 'pt': 0.6483428652623352, 'ta': 0.11484474691620587, 'ur': 0.06366568503716168, 'vi': 0.42992746921092345, 'zh': 0.23226464902209004}\n",
      "{'ar': 0.19470439375668744, 'en': 0.8011197709559408, 'es': 0.30471278317152106, 'eu': 0.32333005639778545, 'fr': 0.26698735280586916, 'hi': 0.1600106284044108, 'mr': 0.34714003944773175, 'pt': 0.3662079357106982, 'ta': 0.221976401179941, 'ur': 0.11828344752975117, 'vi': 0.2700426496787777, 'zh': 0.22634787578586396}\n",
      "{'ar': 0.2494906437396142, 'en': 0.8412396976717688, 'es': 0.5718613630357293, 'eu': 0.33538723574792106, 'fr': 0.625277617833347, 'hi': 0.25902007038168523, 'mr': 0.3248407643312102, 'pt': 0.6186504927975739, 'ta': 0.2629043358568479, 'ur': 0.18192390762585148, 'vi': 0.4515515515515515, 'zh': 0.2875191092907208}\n",
      "{'ar': 0.27893525794973034, 'en': 0.8504083570750237, 'es': 0.6596787638254724, 'eu': 0.3555959267581393, 'fr': 0.6971749500964238, 'hi': 0.29716766310403975, 'mr': 0.3069767441860465, 'pt': 0.6699553801575027, 'ta': 0.22200584225900682, 'ur': 0.2086873279885126, 'vi': 0.4460253940022726, 'zh': 0.17789214109574353}\n",
      "{'ar': 0.35687479642558734, 'en': 0.8463017302438531, 'es': 0.7071290944123315, 'eu': 0.3549286297880521, 'fr': 0.7215388326097444, 'hi': 0.36482110262801515, 'mr': 0.3197492163009404, 'pt': 0.6853248491186402, 'ta': 0.2112728630085853, 'ur': 0.305193206989909, 'vi': 0.39343786295005806, 'zh': 0.26845861525627956}\n",
      "{'ar': 0.2634427520568374, 'en': 0.8432011645201101, 'es': 0.7278070780757098, 'eu': 0.3644519883608147, 'fr': 0.7283981383569856, 'hi': 0.39436532443792666, 'mr': 0.36334913112164297, 'pt': 0.7115405051184868, 'ta': 0.21756021756021754, 'ur': 0.2761805586996876, 'vi': 0.38475570674949466, 'zh': 0.1536379928315412}\n",
      "{'ar': 0.3008503792231671, 'en': 0.8409083714775915, 'es': 0.7015486560941107, 'eu': 0.37143921519930456, 'fr': 0.7150161463939722, 'hi': 0.21422448358819787, 'mr': 0.35094339622641507, 'pt': 0.6665535471886833, 'ta': 0.1619391438886024, 'ur': 0.29995200069817163, 'vi': 0.45281534300467174, 'zh': 0.1387998016201025}\n",
      "{'ar': 0.2494906437396142, 'en': 0.8412396976717688, 'es': 0.5718613630357293, 'eu': 0.33538723574792106, 'fr': 0.625277617833347, 'hi': 0.25902007038168523, 'mr': 0.3248407643312102, 'pt': 0.6186504927975739, 'ta': 0.2629043358568479, 'ur': 0.18192390762585148, 'vi': 0.4515515515515515, 'zh': 0.2875191092907208}\n",
      "{'ar': 0.13775416742993224, 'en': 0.6936520041880486, 'es': 0.19489696798926304, 'eu': 0.26555358888331176, 'fr': 0.1744657120831898, 'hi': 0.08384465247829084, 'mr': 0.3147540983606557, 'pt': 0.25055218540986157, 'ta': 0.20082120194102274, 'ur': 0.06169031462060457, 'vi': 0.25200070097552424, 'zh': 0.05114426016862782}\n",
      "{'best': 39.034200379203114, '1000': 30.007194456874824, '10000': 41.747223248865176, '100000': 43.087531237482615, '200000': 46.1252566644333, '300000': 45.23908798241212, '400000': 43.458254038358255, '500000': 41.747223248865176, '600000': 22.34274878773611}\n"
     ]
    }
   ],
   "source": [
    "# ======================read f1 scores==============================\n",
    "# Dict{checkpoint: avg_f1_score}\n",
    "avg_f1_dict = {}\n",
    "fig, ax1 = plt.subplots(figsize=(8, 5) )\n",
    "\n",
    "for ckpt in checkpoints:\n",
    "    f1_dict = {}\n",
    "    if ckpt == 'best':\n",
    "        output_file_name = os.path.join(output_file_path, model + output_file_suffix, 'test_results.txt')\n",
    "    else:\n",
    "        ckpt_affix = '-intermediate-global_step' + ckpt\n",
    "        output_file_name = os.path.join(output_file_path, model + ckpt_affix + output_file_suffix, 'test_results.txt')\n",
    "    with open(output_file_name, 'r') as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if 'language' in line:\n",
    "                lang = line.split('=')[1].split('\\n')[0]\n",
    "                f1_score = float(f.readline().split(' = ')[1])\n",
    "                if lang in langs:\n",
    "                    f1_dict[lang] = f1_score \n",
    "        print(f1_dict)\n",
    "        avg_f1_score = sum(f1_dict.values())/len(f1_dict.values()) * 100\n",
    "        avg_f1_dict[ckpt] = avg_f1_score\n",
    "\n",
    "print(avg_f1_dict)\n",
    "# plotting\n",
    "# ckpts, f1_scores = zip(*avg_f1_dict.items())\n",
    "# ax1.set_xlabel('global steps')\n",
    "# ax1.set_ylabel('F1 scores', color='r')\n",
    "# ax1.tick_params(axis='y', labelcolor='r', grid_alpha=0.5)\n",
    "# ax1.plot(ckpts, f1_scores, 'r-')                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop over checkpoints\n",
      "defaultdict(<class 'dict'>, {'Gender': {'best': 0.2307142857142857, '1000': 0.08142857142857143, '10000': 0.1042857142857143, '100000': 0.1542857142857143, '200000': 0.17642857142857143, '300000': 0.20857142857142855, '400000': 0.2, '500000': 0.09428571428571429, '600000': 0.05857142857142859}, 'Number': {'best': 0.18145454545454545, '1000': 0.07418181818181817, '10000': 0.10763636363636361, '100000': 0.144, '200000': 0.14509090909090908, '300000': 0.1549090909090909, '400000': 0.16472727272727275, '500000': 0.10254545454545454, '600000': 0.05381818181818182}, 'POS': {'best': 0.13333333333333336, '1000': 0.06256410256410255, '10000': 0.06974358974358971, '100000': 0.09230769230769229, '200000': 0.09384615384615383, '300000': 0.1058974358974359, '400000': 0.13487179487179488, '500000': 0.06641025641025641, '600000': 0.04923076923076923}})\n"
     ]
    }
   ],
   "source": [
    "# ===========================read overlap ratios============================\n",
    "# Dict{attr: Dict{checkpoint: avg_overlap_rate}}\n",
    "avg_overlap_rates: Dict[str, Dict[str, float]] = defaultdict(dict)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "if layers is not None:\n",
    "    print(\"Loop over layers\")\n",
    "    for layer in layers:\n",
    "        embedding = model\n",
    "        experiment_name = f\"inter-layer-{layer}\"\n",
    "        if layer == 25:\n",
    "            experiment_name = \"last-layer\"\n",
    "        DEFAULT_RESULTS_FOLDER = f\"results/{embedding}/{experiment_name}\"\n",
    "\n",
    "        # print(listdir(DEFAULT_RESULTS_FOLDER))\n",
    "        RESULTS = []\n",
    "        rel_treebanks = []\n",
    "        for lang in listdir(DEFAULT_RESULTS_FOLDER):\n",
    "            if lang == 'UD_Chinese-CFL':\n",
    "                continue\n",
    "            rel_treebanks.append(lang)\n",
    "            for attr in listdir(join(DEFAULT_RESULTS_FOLDER, lang)):\n",
    "                RESULTS.append((lang, attr))\n",
    "                \n",
    "        # embedding, attribute, language\n",
    "\n",
    "        DEFAULT_FILE_FORMAT = join(DEFAULT_RESULTS_FOLDER, \"{lang}/{attribute}/loginfo.json\")\n",
    "\n",
    "        results_raw: List[Tuple[Dict[str, Any], List[int]]] = []\n",
    "\n",
    "        for l, a in RESULTS:  # noqa\n",
    "            if l in rel_treebanks:\n",
    "                with open(DEFAULT_FILE_FORMAT.format(lang=l, attribute=a), \"r\") as h:\n",
    "                    data = json.load(h)\n",
    "\n",
    "                results_raw.append(\n",
    "                    (\n",
    "                        { \"embedding\": embedding, \"attribute\": a,\n",
    "                        \"language\": convert_language_code(l) },\n",
    "                        [d[\"iteration_dimension\"] for d in data if \"iteration_dimension\" in d]\n",
    "                        if not random_baseline else random.sample(range(embedding_size), k=top_k)\n",
    "                    )\n",
    "            )\n",
    "        # Compute p values\n",
    "        num_permutations = 1000000\n",
    "        p_vals_cache_file = f\"{embedding}_{top_k}_{num_permutations}_pvals.pkl\"\n",
    "        if not os.path.exists(p_vals_cache_file):\n",
    "            # Compute p-values for different similarities\n",
    "            # if embedding in [\"bert-base-multilingual-cased\", \"xlm-roberta-base\"]:\n",
    "            #     dimensionality = 768\n",
    "            # elif embedding == \"xlm-roberta-large\":\n",
    "            #     dimensionality = 1024\n",
    "            # elif 'bloom' in embedding:\n",
    "            #     dimensionality = 1024\n",
    "            # else:\n",
    "            #     raise Exception(\"Embedding does not exist\")\n",
    "            #     dimensionality = 300\n",
    "            dimensionality = embedding_size\n",
    "\n",
    "            reference_order = random.sample(list(range(dimensionality)), dimensionality)\n",
    "            reference_top_k = reference_order[:top_k]\n",
    "            similarities = []\n",
    "\n",
    "            for i in tqdm(range(num_permutations)):\n",
    "                permuted_top_k = random.sample(reference_order, top_k)\n",
    "                similarities.append(compute_overlap_coefficient(set(reference_top_k), set(permuted_top_k)))\n",
    "                pvals = {}\n",
    "\n",
    "            for i in range(top_k + 1):\n",
    "                observed_hypothesis = i / top_k  # What is overlap score greater than or equal to?\n",
    "                permutations_match = [s for s in similarities if s >= observed_hypothesis]\n",
    "                pval = len(permutations_match) / num_permutations\n",
    "                print(f\"P-value when sim >= {observed_hypothesis} (overlap >= {i} dims): {pval:.5f}\")\n",
    "                pvals[i] = pval\n",
    "\n",
    "            with open(p_vals_cache_file, \"wb\") as h:\n",
    "                pickle.dump(pvals, h)\n",
    "        else:\n",
    "            with open(p_vals_cache_file, \"rb\") as h:\n",
    "                pvals = pickle.load(h)\n",
    "\n",
    "        for attr in attributes:\n",
    "            labels, (similarity_matrix, extra_data) = compute_similarity_for_attribute(\n",
    "                attr, results_raw, top_k)\n",
    "            \n",
    "            # get the average pairwise overlap:\n",
    "            print(len(labels))\n",
    "            print(similarity_matrix)\n",
    "            avg_overlap_rates[attr][layer] = np.average(similarity_matrix[np.triu_indices(len(labels), k = 1)])\n",
    "            \n",
    "\n",
    "            x_labels = labels\n",
    "            y_labels = labels\n",
    "\n",
    "            p_values_matrix = compute_pvalues(extra_data[\"overlap_num\"], pvals)\n",
    "            annotation_matrix = build_statistical_significance_matrix(\n",
    "                p_values_matrix, alpha=0.05, method=\"holm-bonferroni\", symmetry=True)\n",
    "    \n",
    "    for attr, overlap_rates in avg_overlap_rates.items():\n",
    "        overlap_rates = sorted(overlap_rates.items()) \n",
    "        print(overlap_rates)\n",
    "        x, y = zip(*overlap_rates)\n",
    "        \n",
    "        plt.plot(x, y, f'o-', label=attr)\n",
    "\n",
    "\n",
    "elif checkpoints is not None:\n",
    "    print(\"Loop over checkpoints\")\n",
    "    for checkpoint in checkpoints:\n",
    "        embedding = f\"{model}-intermediate-global_step{checkpoint}\"\n",
    "        if checkpoint == 'best':\n",
    "            embedding = model\n",
    "        DEFAULT_RESULTS_FOLDER = f\"results/{embedding}/{experiment_name}\"\n",
    "\n",
    "        # print(listdir(DEFAULT_RESULTS_FOLDER))\n",
    "        RESULTS = []\n",
    "        rel_treebanks = []\n",
    "        for lang in listdir(DEFAULT_RESULTS_FOLDER):\n",
    "            if lang == 'UD_Chinese-CFL':\n",
    "                continue\n",
    "            rel_treebanks.append(lang)\n",
    "            for attr in listdir(join(DEFAULT_RESULTS_FOLDER, lang)):\n",
    "                RESULTS.append((lang, attr))\n",
    "                \n",
    "        # embedding, attribute, language\n",
    "\n",
    "        DEFAULT_FILE_FORMAT = join(DEFAULT_RESULTS_FOLDER, \"{lang}/{attribute}/loginfo.json\")\n",
    "\n",
    "        results_raw: List[Tuple[Dict[str, Any], List[int]]] = []\n",
    "\n",
    "        for l, a in RESULTS:  # noqa\n",
    "            if l in rel_treebanks:\n",
    "                with open(DEFAULT_FILE_FORMAT.format(lang=l, attribute=a), \"r\") as h:\n",
    "                    data = json.load(h)\n",
    "\n",
    "                results_raw.append(\n",
    "                    (\n",
    "                        { \"embedding\": embedding, \"attribute\": a,\n",
    "                        \"language\": convert_language_code(l) },\n",
    "                        [d[\"iteration_dimension\"] for d in data if \"iteration_dimension\" in d]\n",
    "                        if not random_baseline else random.sample(range(embedding_size), k=top_k)\n",
    "                    )\n",
    "            )\n",
    "        # Compute p values\n",
    "        num_permutations = 1000000\n",
    "        p_vals_cache_file = f\"{embedding}_{top_k}_{num_permutations}_pvals.pkl\"\n",
    "        if not os.path.exists(p_vals_cache_file):\n",
    "            # Compute p-values for different similarities\n",
    "            # if embedding in [\"bert-base-multilingual-cased\", \"xlm-roberta-base\"]:\n",
    "            #     dimensionality = 768\n",
    "            # elif embedding == \"xlm-roberta-large\":\n",
    "            #     dimensionality = 1024\n",
    "            # elif 'bloom' in embedding:\n",
    "            #     dimensionality = 1024\n",
    "            # else:\n",
    "            #     raise Exception(\"Embedding does not exist\")\n",
    "            #     dimensionality = 300\n",
    "            dimensionality = embedding_size\n",
    "\n",
    "            reference_order = random.sample(list(range(dimensionality)), dimensionality)\n",
    "            reference_top_k = reference_order[:top_k]\n",
    "            similarities = []\n",
    "\n",
    "            for i in tqdm(range(num_permutations)):\n",
    "                permuted_top_k = random.sample(reference_order, top_k)\n",
    "                similarities.append(compute_overlap_coefficient(set(reference_top_k), set(permuted_top_k)))\n",
    "                pvals = {}\n",
    "\n",
    "            for i in range(top_k + 1):\n",
    "                observed_hypothesis = i / top_k  # What is overlap score greater than or equal to?\n",
    "                permutations_match = [s for s in similarities if s >= observed_hypothesis]\n",
    "                pval = len(permutations_match) / num_permutations\n",
    "                print(f\"P-value when sim >= {observed_hypothesis} (overlap >= {i} dims): {pval:.5f}\")\n",
    "                pvals[i] = pval\n",
    "\n",
    "            with open(p_vals_cache_file, \"wb\") as h:\n",
    "                pickle.dump(pvals, h)\n",
    "        else:\n",
    "            with open(p_vals_cache_file, \"rb\") as h:\n",
    "                pvals = pickle.load(h)\n",
    "\n",
    "        for attr in attributes:\n",
    "            labels, (similarity_matrix, extra_data) = compute_similarity_for_attribute(\n",
    "                attr, results_raw, top_k)\n",
    "            \n",
    "            # get the average pairwise overlap:\n",
    "            # print(len(labels))\n",
    "            # print(similarity_matrix)\n",
    "            if checkpoint == 'best':\n",
    "                avg_overlap_rates[attr][checkpoint] = np.average(similarity_matrix[np.triu_indices(len(labels), k = 1)])\n",
    "            else:\n",
    "                avg_overlap_rates[attr][checkpoint] = np.average(similarity_matrix[np.triu_indices(len(labels), k = 1)])\n",
    "\n",
    "            x_labels = labels\n",
    "            y_labels = labels\n",
    "\n",
    "            p_values_matrix = compute_pvalues(extra_data[\"overlap_num\"], pvals)\n",
    "            annotation_matrix = build_statistical_significance_matrix(\n",
    "                p_values_matrix, alpha=0.05, method=\"holm-bonferroni\", symmetry=True)\n",
    "    \n",
    "    for attr, overlap_rates in avg_overlap_rates.items():\n",
    "        \n",
    "        if 'best' in overlap_rates.keys():\n",
    "            rate_for_best_checkpoint = [overlap_rates['best']]*8\n",
    "            # del overlap_rates['best']\n",
    "            # plt.plot(x, rate_for_best_checkpoint, f'-{color}', label=f'{model}-{attr}')\n",
    "            \n",
    "        # overlap_rates = sorted(overlap_rates.items()) \n",
    "        # x, y = zip(*overlap_rates)\n",
    "        \n",
    "        shape = shapes[attr]\n",
    "        \n",
    "        # ax2.plot(x, y, f'{shape}--', label=attr)      \n",
    "    \n",
    "else: \n",
    "    print(\"no x axises. please check.\")\n",
    "\n",
    "print(avg_overlap_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best': 0.18183405483405482, '1000': 0.07272483072483071, '10000': 0.09388855588855587, '100000': 0.1301978021978022, '200000': 0.13845521145521145, '300000': 0.15645931845931846, '400000': 0.16653302253302257, '500000': 0.08774714174714175, '600000': 0.05387345987345987}\n"
     ]
    }
   ],
   "source": [
    "ckpts_avg_overlap_rates = {}\n",
    "\n",
    "for ckpt in checkpoints:\n",
    "    ckpt_sum_rates = 0\n",
    "    for attr in attributes:\n",
    "        ckpt_sum_rates += avg_overlap_rates[attr][ckpt]\n",
    "    ckpts_avg_overlap_rates[ckpt] = ckpt_sum_rates/len(attributes)\n",
    "\n",
    "print(ckpts_avg_overlap_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"f1_rate_ckpts.txt\", 'a+') as f: \n",
    "    for ckpt in checkpoints:\n",
    "        f.write('%s %s %s\\n' % (avg_f1_dict[ckpt], ckpts_avg_overlap_rates[ckpt], ckpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.legend(loc='center left', bbox_to_anchor=(1.2, 0.5))\n",
    "# ax2.set_ylabel('overlap rates')\n",
    "# fig.gca().yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "# # fig.gca().yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "# if layers is not None:\n",
    "#     fig.xlabel(\"layer\")\n",
    "    \n",
    "# plt.style.use('seaborn-darkgrid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.tight_layout()\n",
    "# sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if layers is not None:\n",
    "#     plt.savefig(f'experiments/scatterplots/{model}/layers.pdf')\n",
    "# elif checkpoints is not None:\n",
    "#     plt.savefig(f'experiments/scatterplots/{model}/checkpoints_{experiment_name}.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilingual-typology-probing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed44db9dbf3c575ec3ddf9da9744b6e2502eab3ed89ccbe6b1ade08a3a1a68bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
