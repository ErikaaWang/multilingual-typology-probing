{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============imports===================\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Set, Optional, Any\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "\n",
    "import pycountry\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "from collections import defaultdict\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "lang_code_dict_2to3 = {'ar':'ara', 'eu':'eus', 'ca':'cat', 'zh':'zho', 'en':'eng', 'fr':'fra', 'hi':'hin', 'mr':'mar', 'pt':'por', 'es':'spa', 'ta':'tam', 'ur':'urd', 'vi':'vie'}\n",
    "lang_code_dict_3to2 = {'ara':'ar', 'eus':'eu', 'cat':'ca', 'zho':'zh', 'eng':'en', 'fra':'fr', 'hin':'hi', 'mar':'mr', 'por':'pt', 'spa':'es', 'tam':'ta', 'urd':'ur', 'vie':'vi'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================args=====================\n",
    "# checkpoints = 'best'\n",
    "# checkpoints = ['best', '10000', '50000', '100000', '150000', '200000', '250000']\n",
    "checkpoints = ['best', '1000', '10000', '100000', '200000', '300000', '400000', '500000', '600000']\n",
    "random_baseline = False\n",
    "embedding_size = 1024\n",
    "top_k = 50\n",
    "attributes = ['Number', 'POS']\n",
    "shapes = {'Gender':'^', 'Number':'o', 'POS':'s'}\n",
    "# attributes = ['Aspect', 'Case', 'Definiteness', 'Finiteness', 'Gender', 'Mood', 'Number',\\\n",
    "#              'Person', 'POS', 'Tense', 'Voice']\n",
    "language = None\n",
    "show_plot = False\n",
    "experiment_name = 'inter-layer-13'\n",
    "# layers = [1, 5, 9, 13, 17, 21, 25]\n",
    "layers = None\n",
    "model = 'bloom-560m'\n",
    "\n",
    "\n",
    "# cross-lingual eval result args\n",
    "output_file_path = 'xtreme/outputs-temp/udpos/'\n",
    "output_file_suffix = '-LR2e-5-epoch10-MaxLen128'\n",
    "langs = ['ar', 'eu', 'ca', 'zh', 'en', 'fr', 'hi', 'mr', 'pt', 'es', 'ta', 'ur', 'vi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================functions====================\n",
    "def convert_language_code(treebank_name):\n",
    "    \"\"\" Converts treebank names to language codes. \"\"\"\n",
    "    lang_name = treebank_name[3:].split(\"-\")[0].replace(\"_\", \" \")\n",
    "    lang = pycountry.languages.get(name=lang_name)\n",
    "\n",
    "    if lang is not None:\n",
    "        return lang.alpha_3.lower()\n",
    "\n",
    "    return \"unk\"\n",
    "\n",
    "def compute_overlap(data_raw, top_k):\n",
    "    mark_count: Dict[str, int] = {}  # num of languages logging that attribute\n",
    "    results: Dict[str, Counter] = {}\n",
    "    for run_config, dims in data_raw:\n",
    "        if run_config[\"embedding\"] != embedding:\n",
    "            continue\n",
    "\n",
    "        # Increment mark counting\n",
    "        if run_config[\"attribute\"] not in mark_count:\n",
    "            mark_count[run_config[\"attribute\"]] = 0\n",
    "\n",
    "        mark_count[run_config[\"attribute\"]] += 1\n",
    "\n",
    "        # Increment actual counters\n",
    "        if run_config[\"attribute\"] not in results:\n",
    "            results[run_config[\"attribute\"]] = Counter()\n",
    "\n",
    "        results[run_config[\"attribute\"]].update(dims[:top_k])\n",
    "\n",
    "    return results, mark_count\n",
    "\n",
    "\n",
    "def compute_similarity_for_attribute(attribute, data_raw, top_k, language_order: Optional[List[str]] = None):\n",
    "    data_list: List[Tuple[str, Set[int]]] = []\n",
    "    for run_config, dims in data_raw:\n",
    "        if run_config[\"embedding\"] != embedding:\n",
    "            continue\n",
    "\n",
    "        if run_config[\"attribute\"] != attribute:\n",
    "            continue\n",
    "\n",
    "        data_list.append((run_config[\"language\"], set(dims[:top_k])))\n",
    "\n",
    "    if not language_order:\n",
    "        data_list = sorted(data_list, key=lambda x: x[0])\n",
    "        return [x[0] for x in data_list], compute_similarity(data_list)\n",
    "    else:\n",
    "        data_list_dict = {k: v for k, v in data_list}\n",
    "        data_list_sorted = []\n",
    "        for x in language_order:\n",
    "            if x in data_list_dict:\n",
    "                data_list_sorted.append((x, data_list_dict[x]))\n",
    "\n",
    "        data_list = data_list_sorted\n",
    "        return [x[0] for x in data_list], compute_similarity(data_list)\n",
    "\n",
    "\n",
    "def compute_similarity_for_language(language, data_raw, top_k):\n",
    "    data_list: List[Tuple[str, Set[int]]] = []\n",
    "    for run_config, dims in data_raw:\n",
    "        if run_config[\"embedding\"] != embedding:\n",
    "            continue\n",
    "\n",
    "        if run_config[\"language\"] != language:\n",
    "            continue\n",
    "\n",
    "        data_list.append((run_config[\"attribute\"], set(dims[:top_k])))\n",
    "\n",
    "    data_list = sorted(data_list, key=lambda x: x[0])\n",
    "\n",
    "    return [x[0] for x in data_list], compute_similarity(data_list)\n",
    "\n",
    "\n",
    "def compute_jaccard_index(set_a: Set[int], set_b: Set[int]) -> float:\n",
    "    return len(set_a & set_b) / len(set_a | set_b)\n",
    "\n",
    "\n",
    "def compute_overlap_coefficient(set_a: Set[int], set_b: Set[int]) -> float:\n",
    "    return len(set_a & set_b) / min(len(set_a), len(set_b))\n",
    "\n",
    "\n",
    "def compute_similarity(data_list: List[Tuple[str, Set[int]]]):\n",
    "    num_items = len(data_list)\n",
    "    similarity_array = np.zeros((num_items, num_items))\n",
    "    extra_data = {\n",
    "        \"overlap\": np.empty((num_items, num_items), dtype=list),\n",
    "        \"overlap_num\": np.zeros((num_items, num_items)),\n",
    "    }\n",
    "    for idx_a, (group_a, dim_set_a) in enumerate(data_list):\n",
    "        for idx_b, (group_b, dim_set_b) in enumerate(data_list):\n",
    "            similarity_array[idx_a, idx_b] = compute_overlap_coefficient(dim_set_a, dim_set_b)\n",
    "            extra_data[\"overlap\"][idx_a, idx_b] = sorted(list(set(dim_set_a & dim_set_b)))\n",
    "            extra_data[\"overlap_num\"][idx_a, idx_b] = len(dim_set_a & dim_set_b)\n",
    "\n",
    "    return similarity_array, extra_data\n",
    "\n",
    "\n",
    "def compute_pvalues(overlap_num_matrix: np.array, p_val_dict: Dict[int, float]) -> np.array:\n",
    "    return np.vectorize(lambda x: p_val_dict[int(x)])(overlap_num_matrix)\n",
    "\n",
    "\n",
    "def build_statistical_significance_matrix(p_values_matrix, alpha=0.05, method=\"bonferroni\", symmetry=False):\n",
    "    num_rows = p_values_matrix.shape[0]\n",
    "    num_hypotheses = int(num_rows * (num_rows + 1) / 2) - num_rows\n",
    "    num_hypotheses = num_hypotheses if num_hypotheses > 0 else 999\n",
    "    alpha_bonferroni = alpha / num_hypotheses\n",
    "\n",
    "    if method == \"bonferroni\":\n",
    "        mask = np.tril(np.ones_like(p_values_matrix, dtype=bool), k=-1)\n",
    "        significance_matrix = (p_values_matrix < alpha_bonferroni) * mask\n",
    "    elif method == \"holm-bonferroni\":\n",
    "        mask = np.triu(np.ones_like(p_values_matrix)) * 9999.0\n",
    "        p_values_matrix += mask\n",
    "        p_values_matrix_flat = p_values_matrix.reshape(-1)\n",
    "        sorting_indices = p_values_matrix_flat.argsort()\n",
    "        unsorting_indices = sorting_indices.argsort()\n",
    "\n",
    "        sorted_p_values = p_values_matrix_flat[sorting_indices][:num_hypotheses]\n",
    "        alpha_holm = np.arange(1.0, num_hypotheses + 1.0)[::-1] ** -1 * alpha\n",
    "\n",
    "        broke = False\n",
    "        for k, (pval, alph) in enumerate(zip(sorted_p_values.tolist(), alpha_holm.tolist())):\n",
    "            if pval > alph:\n",
    "                broke = True\n",
    "                break\n",
    "\n",
    "        if not broke:\n",
    "            # Needed in case we never accepted the null hypothesis\n",
    "            k += 1\n",
    "\n",
    "        # k will be equal to the first index where we do NOT reject the null hypothesis.\n",
    "        # So we can accept the alternative hypothesis on all indices less than k\n",
    "        # e.g., if k == 0, we always accept the null hypothesis. If k == num_hypothesis\n",
    "        # we always reject the null hypothesis.\n",
    "        rejected_null_sorted = [True if idx < k else False for idx in range(num_hypotheses)]\n",
    "\n",
    "        # Pad remaining list with rejections\n",
    "        rejected_null_sorted.extend([False] * (num_rows ** 2 - num_hypotheses))\n",
    "\n",
    "        # Reverse sort\n",
    "        significance_matrix = np.array(rejected_null_sorted)[unsorting_indices].reshape(num_rows, num_rows)\n",
    "\n",
    "    if symmetry:\n",
    "        # Mirror along diagonal\n",
    "        significance_matrix = significance_matrix | significance_matrix.T\n",
    "\n",
    "    return significance_matrix\n",
    "\n",
    "\n",
    "def build_annotations_list(annotation_matrix):\n",
    "    n = annotation_matrix.shape[0]\n",
    "    annotation_list = []\n",
    "    for x in range(n):\n",
    "        for y in range(n):\n",
    "            if not annotation_matrix[x][y]:\n",
    "                continue\n",
    "\n",
    "            if x == y:\n",
    "                continue\n",
    "\n",
    "            annotation_list.append(\n",
    "                dict(\n",
    "                    x=x / n, y=y / n,\n",
    "                    xref='paper',\n",
    "                    yref='paper',\n",
    "                    text=\"■\",\n",
    "                    showarrow=False,\n",
    "                    xanchor=\"left\",\n",
    "                    yanchor=\"bottom\",\n",
    "                    font=dict(color=\"rgb(236,136,106)\")\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return annotation_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'xtreme/outputs-temp/udpos/bloom-1b7-LR2e-5-epoch10-MaxLen128/test_results.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/multilingual-typology-probing/write_file.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bconnect.westb.seetacloud.com/root/multilingual-typology-probing/write_file.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     ckpt_affix \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-intermediate-global_step\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m ckpt\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bconnect.westb.seetacloud.com/root/multilingual-typology-probing/write_file.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     output_file_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_file_path, model \u001b[39m+\u001b[39m ckpt_affix \u001b[39m+\u001b[39m output_file_suffix, \u001b[39m'\u001b[39m\u001b[39mtest_results.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bconnect.westb.seetacloud.com/root/multilingual-typology-probing/write_file.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(output_file_name, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bconnect.westb.seetacloud.com/root/multilingual-typology-probing/write_file.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bconnect.westb.seetacloud.com/root/multilingual-typology-probing/write_file.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m         line \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreadline()\n",
      "File \u001b[0;32m~/miniconda3/envs/xtreme/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'xtreme/outputs-temp/udpos/bloom-1b7-LR2e-5-epoch10-MaxLen128/test_results.txt'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ======================read f1 scores==============================\n",
    "# Dict{checkpoint: avg_f1_score}\n",
    "avg_f1_dict = {}\n",
    "# Dict{ckpt: Dict{lang: f1_score}}\n",
    "ckpt_lan_f1_dict: Dict[str, Dict[str, float]] = defaultdict(dict)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(8, 5) )\n",
    "\n",
    "for ckpt in checkpoints:\n",
    "    f1_dict = {}\n",
    "    if ckpt == 'best':\n",
    "        output_file_name = os.path.join(output_file_path, model + output_file_suffix, 'test_results.txt')\n",
    "    else:\n",
    "        ckpt_affix = '-intermediate-global_step' + ckpt\n",
    "        output_file_name = os.path.join(output_file_path, model + ckpt_affix + output_file_suffix, 'test_results.txt')\n",
    "    with open(output_file_name, 'r') as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if 'language' in line:\n",
    "                lang = line.split('=')[1].split('\\n')[0]\n",
    "                f1_score = float(f.readline().split(' = ')[1])\n",
    "                if lang in langs:\n",
    "                    f1_dict[lang] = f1_score \n",
    "        print(f1_dict)\n",
    "        ckpt_lan_f1_dict[ckpt] = f1_dict\n",
    "        avg_f1_score = sum(f1_dict.values())/len(f1_dict.values()) * 100\n",
    "        avg_f1_dict[ckpt] = avg_f1_score\n",
    "\n",
    "print(avg_f1_dict)\n",
    "print(ckpt_lan_f1_dict)\n",
    "# plotting\n",
    "# ckpts, f1_scores = zip(*avg_f1_dict.items())\n",
    "# ax1.set_xlabel('global steps')\n",
    "# ax1.set_ylabel('F1 scores', color='r')\n",
    "# ax1.tick_params(axis='y', labelcolor='r', grid_alpha=0.5)\n",
    "# ax1.plot(ckpts, f1_scores, 'r-')                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop over checkpoints\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd']\n",
      "[[1.   0.18 0.32 0.18 0.2  0.2  0.04 0.18 0.18 0.1  0.14]\n",
      " [0.18 1.   0.38 0.16 0.46 0.28 0.1  0.44 0.5  0.16 0.24]\n",
      " [0.32 0.38 1.   0.16 0.26 0.2  0.06 0.32 0.3  0.16 0.2 ]\n",
      " [0.18 0.16 0.16 1.   0.16 0.12 0.04 0.16 0.18 0.26 0.1 ]\n",
      " [0.2  0.46 0.26 0.16 1.   0.22 0.12 0.34 0.4  0.12 0.16]\n",
      " [0.2  0.28 0.2  0.12 0.22 1.   0.1  0.26 0.2  0.06 0.3 ]\n",
      " [0.04 0.1  0.06 0.04 0.12 0.1  1.   0.06 0.12 0.02 0.1 ]\n",
      " [0.18 0.44 0.32 0.16 0.34 0.26 0.06 1.   0.56 0.1  0.14]\n",
      " [0.18 0.5  0.3  0.18 0.4  0.2  0.12 0.56 1.   0.12 0.18]\n",
      " [0.1  0.16 0.16 0.26 0.12 0.06 0.02 0.1  0.12 1.   0.06]\n",
      " [0.14 0.24 0.2  0.1  0.16 0.3  0.1  0.14 0.18 0.06 1.  ]]\n",
      "[0.32, 0.38, 1.0, 0.16, 0.26, 0.2, 0.06, 0.32, 0.3, 0.16, 0.2]\n",
      "<class 'list'>\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd', 'vie', 'zho']\n",
      "[[1.   0.16 0.22 0.04 0.18 0.14 0.06 0.2  0.18 0.1  0.12 0.12 0.12]\n",
      " [0.16 1.   0.24 0.08 0.3  0.14 0.04 0.28 0.18 0.12 0.16 0.1  0.16]\n",
      " [0.22 0.24 1.   0.14 0.26 0.14 0.04 0.36 0.2  0.08 0.22 0.08 0.18]\n",
      " [0.04 0.08 0.14 1.   0.1  0.14 0.04 0.08 0.08 0.06 0.16 0.06 0.16]\n",
      " [0.18 0.3  0.26 0.1  1.   0.14 0.02 0.4  0.24 0.12 0.12 0.16 0.22]\n",
      " [0.14 0.14 0.14 0.14 0.14 1.   0.04 0.16 0.1  0.16 0.32 0.04 0.14]\n",
      " [0.06 0.04 0.04 0.04 0.02 0.04 1.   0.04 0.02 0.04 0.02 0.08 0.06]\n",
      " [0.2  0.28 0.36 0.08 0.4  0.16 0.04 1.   0.22 0.14 0.12 0.12 0.24]\n",
      " [0.18 0.18 0.2  0.08 0.24 0.1  0.02 0.22 1.   0.14 0.14 0.12 0.1 ]\n",
      " [0.1  0.12 0.08 0.06 0.12 0.16 0.04 0.14 0.14 1.   0.1  0.1  0.12]\n",
      " [0.12 0.16 0.22 0.16 0.12 0.32 0.02 0.12 0.14 0.1  1.   0.   0.1 ]\n",
      " [0.12 0.1  0.08 0.06 0.16 0.04 0.08 0.12 0.12 0.1  0.   1.   0.12]\n",
      " [0.12 0.16 0.18 0.16 0.22 0.14 0.06 0.24 0.1  0.12 0.1  0.12 1.  ]]\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd']\n",
      "[[1.   0.08 0.08 0.02 0.1  0.08 0.06 0.02 0.04 0.04 0.04]\n",
      " [0.08 1.   0.12 0.06 0.32 0.02 0.   0.24 0.26 0.04 0.04]\n",
      " [0.08 0.12 1.   0.02 0.18 0.04 0.   0.06 0.08 0.06 0.02]\n",
      " [0.02 0.06 0.02 1.   0.   0.04 0.02 0.   0.1  0.02 0.1 ]\n",
      " [0.1  0.32 0.18 0.   1.   0.   0.   0.18 0.16 0.06 0.04]\n",
      " [0.08 0.02 0.04 0.04 0.   1.   0.02 0.04 0.04 0.14 0.08]\n",
      " [0.06 0.   0.   0.02 0.   0.02 1.   0.02 0.   0.06 0.08]\n",
      " [0.02 0.24 0.06 0.   0.18 0.04 0.02 1.   0.32 0.1  0.1 ]\n",
      " [0.04 0.26 0.08 0.1  0.16 0.04 0.   0.32 1.   0.04 0.02]\n",
      " [0.04 0.04 0.06 0.02 0.06 0.14 0.06 0.1  0.04 1.   0.02]\n",
      " [0.04 0.04 0.02 0.1  0.04 0.08 0.08 0.1  0.02 0.02 1.  ]]\n",
      "[0.08, 0.12, 1.0, 0.02, 0.18, 0.04, 0.0, 0.06, 0.08, 0.06, 0.02]\n",
      "<class 'list'>\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd', 'vie', 'zho']\n",
      "[[1.   0.02 0.06 0.1  0.08 0.06 0.02 0.08 0.04 0.06 0.02 0.02 0.08]\n",
      " [0.02 1.   0.   0.06 0.12 0.02 0.08 0.08 0.1  0.06 0.08 0.08 0.06]\n",
      " [0.06 0.   1.   0.04 0.02 0.08 0.   0.06 0.12 0.06 0.1  0.08 0.04]\n",
      " [0.1  0.06 0.04 1.   0.06 0.08 0.04 0.06 0.06 0.06 0.02 0.08 0.06]\n",
      " [0.08 0.12 0.02 0.06 1.   0.06 0.02 0.18 0.1  0.06 0.1  0.08 0.12]\n",
      " [0.06 0.02 0.08 0.08 0.06 1.   0.1  0.08 0.08 0.04 0.   0.02 0.04]\n",
      " [0.02 0.08 0.   0.04 0.02 0.1  1.   0.02 0.04 0.04 0.02 0.02 0.02]\n",
      " [0.08 0.08 0.06 0.06 0.18 0.08 0.02 1.   0.08 0.04 0.1  0.08 0.08]\n",
      " [0.04 0.1  0.12 0.06 0.1  0.08 0.04 0.08 1.   0.1  0.08 0.02 0.04]\n",
      " [0.06 0.06 0.06 0.06 0.06 0.04 0.04 0.04 0.1  1.   0.02 0.06 0.06]\n",
      " [0.02 0.08 0.1  0.02 0.1  0.   0.02 0.1  0.08 0.02 1.   0.04 0.06]\n",
      " [0.02 0.08 0.08 0.08 0.08 0.02 0.02 0.08 0.02 0.06 0.04 1.   0.04]\n",
      " [0.08 0.06 0.04 0.06 0.12 0.04 0.02 0.08 0.04 0.06 0.06 0.04 1.  ]]\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd']\n",
      "[[1.   0.1  0.1  0.06 0.08 0.02 0.02 0.04 0.1  0.04 0.02]\n",
      " [0.1  1.   0.2  0.06 0.24 0.08 0.04 0.24 0.22 0.08 0.08]\n",
      " [0.1  0.2  1.   0.02 0.22 0.1  0.04 0.16 0.12 0.1  0.12]\n",
      " [0.06 0.06 0.02 1.   0.08 0.   0.04 0.   0.06 0.06 0.02]\n",
      " [0.08 0.24 0.22 0.08 1.   0.08 0.02 0.24 0.28 0.08 0.16]\n",
      " [0.02 0.08 0.1  0.   0.08 1.   0.04 0.14 0.12 0.06 0.12]\n",
      " [0.02 0.04 0.04 0.04 0.02 0.04 1.   0.06 0.06 0.   0.04]\n",
      " [0.04 0.24 0.16 0.   0.24 0.14 0.06 1.   0.32 0.04 0.12]\n",
      " [0.1  0.22 0.12 0.06 0.28 0.12 0.06 0.32 1.   0.1  0.06]\n",
      " [0.04 0.08 0.1  0.06 0.08 0.06 0.   0.04 0.1  1.   0.04]\n",
      " [0.02 0.08 0.12 0.02 0.16 0.12 0.04 0.12 0.06 0.04 1.  ]]\n",
      "[0.1, 0.2, 1.0, 0.02, 0.22, 0.1, 0.04, 0.16, 0.12, 0.1, 0.12]\n",
      "<class 'list'>\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd', 'vie', 'zho']\n",
      "[[1.   0.12 0.06 0.04 0.06 0.14 0.12 0.04 0.08 0.04 0.06 0.12 0.06]\n",
      " [0.12 1.   0.12 0.1  0.18 0.08 0.1  0.12 0.1  0.06 0.08 0.06 0.06]\n",
      " [0.06 0.12 1.   0.1  0.18 0.04 0.02 0.14 0.1  0.02 0.06 0.06 0.18]\n",
      " [0.04 0.1  0.1  1.   0.2  0.06 0.06 0.16 0.1  0.06 0.1  0.1  0.02]\n",
      " [0.06 0.18 0.18 0.2  1.   0.1  0.04 0.16 0.08 0.02 0.04 0.1  0.08]\n",
      " [0.14 0.08 0.04 0.06 0.1  1.   0.   0.02 0.02 0.04 0.04 0.08 0.04]\n",
      " [0.12 0.1  0.02 0.06 0.04 0.   1.   0.04 0.06 0.04 0.06 0.08 0.1 ]\n",
      " [0.04 0.12 0.14 0.16 0.16 0.02 0.04 1.   0.12 0.   0.06 0.06 0.16]\n",
      " [0.08 0.1  0.1  0.1  0.08 0.02 0.06 0.12 1.   0.06 0.04 0.08 0.1 ]\n",
      " [0.04 0.06 0.02 0.06 0.02 0.04 0.04 0.   0.06 1.   0.02 0.02 0.02]\n",
      " [0.06 0.08 0.06 0.1  0.04 0.04 0.06 0.06 0.04 0.02 1.   0.1  0.06]\n",
      " [0.12 0.06 0.06 0.1  0.1  0.08 0.08 0.06 0.08 0.02 0.1  1.   0.06]\n",
      " [0.06 0.06 0.18 0.02 0.08 0.04 0.1  0.16 0.1  0.02 0.06 0.06 1.  ]]\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd']\n",
      "[[1.   0.08 0.16 0.08 0.1  0.1  0.06 0.1  0.08 0.12 0.06]\n",
      " [0.08 1.   0.2  0.14 0.3  0.08 0.1  0.38 0.36 0.04 0.1 ]\n",
      " [0.16 0.2  1.   0.1  0.24 0.12 0.06 0.14 0.16 0.12 0.14]\n",
      " [0.08 0.14 0.1  1.   0.12 0.1  0.02 0.1  0.1  0.18 0.16]\n",
      " [0.1  0.3  0.24 0.12 1.   0.2  0.04 0.2  0.22 0.1  0.14]\n",
      " [0.1  0.08 0.12 0.1  0.2  1.   0.06 0.06 0.12 0.12 0.16]\n",
      " [0.06 0.1  0.06 0.02 0.04 0.06 1.   0.04 0.04 0.02 0.02]\n",
      " [0.1  0.38 0.14 0.1  0.2  0.06 0.04 1.   0.46 0.06 0.1 ]\n",
      " [0.08 0.36 0.16 0.1  0.22 0.12 0.04 0.46 1.   0.12 0.1 ]\n",
      " [0.12 0.04 0.12 0.18 0.1  0.12 0.02 0.06 0.12 1.   0.18]\n",
      " [0.06 0.1  0.14 0.16 0.14 0.16 0.02 0.1  0.1  0.18 1.  ]]\n",
      "[0.16, 0.2, 1.0, 0.1, 0.24, 0.12, 0.06, 0.14, 0.16, 0.12, 0.14]\n",
      "<class 'list'>\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd', 'vie', 'zho']\n",
      "[[1.   0.1  0.06 0.06 0.1  0.06 0.04 0.16 0.1  0.04 0.06 0.08 0.08]\n",
      " [0.1  1.   0.16 0.08 0.2  0.02 0.   0.16 0.18 0.08 0.1  0.1  0.14]\n",
      " [0.06 0.16 1.   0.08 0.18 0.04 0.02 0.14 0.16 0.08 0.08 0.04 0.1 ]\n",
      " [0.06 0.08 0.08 1.   0.14 0.06 0.08 0.12 0.06 0.04 0.06 0.08 0.04]\n",
      " [0.1  0.2  0.18 0.14 1.   0.06 0.02 0.3  0.1  0.08 0.06 0.1  0.1 ]\n",
      " [0.06 0.02 0.04 0.06 0.06 1.   0.06 0.04 0.06 0.1  0.12 0.   0.14]\n",
      " [0.04 0.   0.02 0.08 0.02 0.06 1.   0.02 0.   0.08 0.04 0.04 0.12]\n",
      " [0.16 0.16 0.14 0.12 0.3  0.04 0.02 1.   0.2  0.02 0.12 0.16 0.1 ]\n",
      " [0.1  0.18 0.16 0.06 0.1  0.06 0.   0.2  1.   0.08 0.06 0.06 0.1 ]\n",
      " [0.04 0.08 0.08 0.04 0.08 0.1  0.08 0.02 0.08 1.   0.12 0.06 0.14]\n",
      " [0.06 0.1  0.08 0.06 0.06 0.12 0.04 0.12 0.06 0.12 1.   0.1  0.12]\n",
      " [0.08 0.1  0.04 0.08 0.1  0.   0.04 0.16 0.06 0.06 0.1  1.   0.04]\n",
      " [0.08 0.14 0.1  0.04 0.1  0.14 0.12 0.1  0.1  0.14 0.12 0.04 1.  ]]\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd']\n",
      "[[1.   0.22 0.26 0.14 0.12 0.14 0.04 0.18 0.22 0.04 0.1 ]\n",
      " [0.22 1.   0.3  0.24 0.32 0.22 0.08 0.34 0.38 0.12 0.16]\n",
      " [0.26 0.3  1.   0.16 0.14 0.12 0.04 0.24 0.18 0.08 0.2 ]\n",
      " [0.14 0.24 0.16 1.   0.2  0.14 0.04 0.2  0.14 0.1  0.12]\n",
      " [0.12 0.32 0.14 0.2  1.   0.16 0.02 0.3  0.32 0.1  0.18]\n",
      " [0.14 0.22 0.12 0.14 0.16 1.   0.1  0.18 0.18 0.12 0.1 ]\n",
      " [0.04 0.08 0.04 0.04 0.02 0.1  1.   0.04 0.02 0.04 0.08]\n",
      " [0.18 0.34 0.24 0.2  0.3  0.18 0.04 1.   0.5  0.08 0.1 ]\n",
      " [0.22 0.38 0.18 0.14 0.32 0.18 0.02 0.5  1.   0.1  0.16]\n",
      " [0.04 0.12 0.08 0.1  0.1  0.12 0.04 0.08 0.1  1.   0.02]\n",
      " [0.1  0.16 0.2  0.12 0.18 0.1  0.08 0.1  0.16 0.02 1.  ]]\n",
      "[0.26, 0.3, 1.0, 0.16, 0.14, 0.12, 0.04, 0.24, 0.18, 0.08, 0.2]\n",
      "<class 'list'>\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd', 'vie', 'zho']\n",
      "[[1.   0.16 0.14 0.04 0.24 0.06 0.08 0.12 0.18 0.04 0.1  0.08 0.12]\n",
      " [0.16 1.   0.18 0.1  0.26 0.02 0.02 0.16 0.12 0.04 0.08 0.06 0.08]\n",
      " [0.14 0.18 1.   0.06 0.28 0.1  0.04 0.2  0.16 0.1  0.12 0.12 0.18]\n",
      " [0.04 0.1  0.06 1.   0.08 0.1  0.06 0.08 0.06 0.06 0.1  0.06 0.08]\n",
      " [0.24 0.26 0.28 0.08 1.   0.1  0.08 0.2  0.24 0.02 0.06 0.1  0.14]\n",
      " [0.06 0.02 0.1  0.1  0.1  1.   0.   0.04 0.08 0.02 0.1  0.14 0.04]\n",
      " [0.08 0.02 0.04 0.06 0.08 0.   1.   0.02 0.   0.08 0.04 0.04 0.04]\n",
      " [0.12 0.16 0.2  0.08 0.2  0.04 0.02 1.   0.18 0.02 0.08 0.18 0.06]\n",
      " [0.18 0.12 0.16 0.06 0.24 0.08 0.   0.18 1.   0.04 0.12 0.1  0.06]\n",
      " [0.04 0.04 0.1  0.06 0.02 0.02 0.08 0.02 0.04 1.   0.08 0.06 0.08]\n",
      " [0.1  0.08 0.12 0.1  0.06 0.1  0.04 0.08 0.12 0.08 1.   0.08 0.1 ]\n",
      " [0.08 0.06 0.12 0.06 0.1  0.14 0.04 0.18 0.1  0.06 0.08 1.   0.04]\n",
      " [0.12 0.08 0.18 0.08 0.14 0.04 0.04 0.06 0.06 0.08 0.1  0.04 1.  ]]\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd']\n",
      "[[1.   0.12 0.22 0.08 0.12 0.12 0.06 0.16 0.16 0.02 0.1 ]\n",
      " [0.12 1.   0.24 0.12 0.32 0.26 0.08 0.36 0.34 0.1  0.16]\n",
      " [0.22 0.24 1.   0.12 0.24 0.08 0.1  0.22 0.24 0.1  0.18]\n",
      " [0.08 0.12 0.12 1.   0.12 0.16 0.1  0.12 0.1  0.14 0.08]\n",
      " [0.12 0.32 0.24 0.12 1.   0.2  0.06 0.22 0.28 0.1  0.1 ]\n",
      " [0.12 0.26 0.08 0.16 0.2  1.   0.12 0.18 0.24 0.18 0.14]\n",
      " [0.06 0.08 0.1  0.1  0.06 0.12 1.   0.1  0.12 0.12 0.08]\n",
      " [0.16 0.36 0.22 0.12 0.22 0.18 0.1  1.   0.5  0.1  0.12]\n",
      " [0.16 0.34 0.24 0.1  0.28 0.24 0.12 0.5  1.   0.12 0.14]\n",
      " [0.02 0.1  0.1  0.14 0.1  0.18 0.12 0.1  0.12 1.   0.1 ]\n",
      " [0.1  0.16 0.18 0.08 0.1  0.14 0.08 0.12 0.14 0.1  1.  ]]\n",
      "[0.22, 0.24, 1.0, 0.12, 0.24, 0.08, 0.1, 0.22, 0.24, 0.1, 0.18]\n",
      "<class 'list'>\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd', 'vie', 'zho']\n",
      "[[1.   0.1  0.12 0.1  0.16 0.12 0.06 0.2  0.22 0.08 0.06 0.22 0.16]\n",
      " [0.1  1.   0.18 0.12 0.24 0.08 0.04 0.18 0.24 0.1  0.08 0.08 0.18]\n",
      " [0.12 0.18 1.   0.14 0.22 0.1  0.02 0.2  0.18 0.16 0.1  0.14 0.22]\n",
      " [0.1  0.12 0.14 1.   0.08 0.1  0.04 0.14 0.08 0.08 0.12 0.1  0.08]\n",
      " [0.16 0.24 0.22 0.08 1.   0.08 0.   0.26 0.24 0.08 0.08 0.08 0.14]\n",
      " [0.12 0.08 0.1  0.1  0.08 1.   0.04 0.12 0.18 0.14 0.16 0.1  0.18]\n",
      " [0.06 0.04 0.02 0.04 0.   0.04 1.   0.02 0.   0.1  0.06 0.02 0.06]\n",
      " [0.2  0.18 0.2  0.14 0.26 0.12 0.02 1.   0.24 0.08 0.16 0.14 0.12]\n",
      " [0.22 0.24 0.18 0.08 0.24 0.18 0.   0.24 1.   0.14 0.12 0.12 0.1 ]\n",
      " [0.08 0.1  0.16 0.08 0.08 0.14 0.1  0.08 0.14 1.   0.06 0.12 0.12]\n",
      " [0.06 0.08 0.1  0.12 0.08 0.16 0.06 0.16 0.12 0.06 1.   0.06 0.1 ]\n",
      " [0.22 0.08 0.14 0.1  0.08 0.1  0.02 0.14 0.12 0.12 0.06 1.   0.16]\n",
      " [0.16 0.18 0.22 0.08 0.14 0.18 0.06 0.12 0.1  0.12 0.1  0.16 1.  ]]\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd']\n",
      "[[1.   0.16 0.22 0.16 0.14 0.18 0.   0.26 0.14 0.08 0.18]\n",
      " [0.16 1.   0.28 0.12 0.32 0.2  0.08 0.42 0.42 0.1  0.18]\n",
      " [0.22 0.28 1.   0.08 0.28 0.14 0.04 0.32 0.26 0.08 0.1 ]\n",
      " [0.16 0.12 0.08 1.   0.06 0.14 0.04 0.16 0.14 0.12 0.08]\n",
      " [0.14 0.32 0.28 0.06 1.   0.18 0.02 0.34 0.32 0.12 0.16]\n",
      " [0.18 0.2  0.14 0.14 0.18 1.   0.06 0.26 0.26 0.22 0.3 ]\n",
      " [0.   0.08 0.04 0.04 0.02 0.06 1.   0.04 0.04 0.08 0.08]\n",
      " [0.26 0.42 0.32 0.16 0.34 0.26 0.04 1.   0.48 0.08 0.14]\n",
      " [0.14 0.42 0.26 0.14 0.32 0.26 0.04 0.48 1.   0.08 0.2 ]\n",
      " [0.08 0.1  0.08 0.12 0.12 0.22 0.08 0.08 0.08 1.   0.1 ]\n",
      " [0.18 0.18 0.1  0.08 0.16 0.3  0.08 0.14 0.2  0.1  1.  ]]\n",
      "[0.22, 0.28, 1.0, 0.08, 0.28, 0.14, 0.04, 0.32, 0.26, 0.08, 0.1]\n",
      "<class 'list'>\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd', 'vie', 'zho']\n",
      "[[1.   0.12 0.2  0.06 0.26 0.18 0.02 0.26 0.18 0.18 0.08 0.16 0.12]\n",
      " [0.12 1.   0.22 0.08 0.26 0.1  0.02 0.24 0.16 0.1  0.08 0.1  0.18]\n",
      " [0.2  0.22 1.   0.04 0.26 0.12 0.06 0.26 0.26 0.14 0.18 0.2  0.16]\n",
      " [0.06 0.08 0.04 1.   0.08 0.08 0.08 0.1  0.14 0.1  0.08 0.04 0.08]\n",
      " [0.26 0.26 0.26 0.08 1.   0.08 0.02 0.36 0.3  0.12 0.14 0.18 0.2 ]\n",
      " [0.18 0.1  0.12 0.08 0.08 1.   0.08 0.14 0.08 0.08 0.18 0.08 0.14]\n",
      " [0.02 0.02 0.06 0.08 0.02 0.08 1.   0.04 0.02 0.06 0.08 0.06 0.04]\n",
      " [0.26 0.24 0.26 0.1  0.36 0.14 0.04 1.   0.28 0.1  0.12 0.22 0.18]\n",
      " [0.18 0.16 0.26 0.14 0.3  0.08 0.02 0.28 1.   0.12 0.06 0.16 0.12]\n",
      " [0.18 0.1  0.14 0.1  0.12 0.08 0.06 0.1  0.12 1.   0.02 0.1  0.08]\n",
      " [0.08 0.08 0.18 0.08 0.14 0.18 0.08 0.12 0.06 0.02 1.   0.1  0.22]\n",
      " [0.16 0.1  0.2  0.04 0.18 0.08 0.06 0.22 0.16 0.1  0.1  1.   0.18]\n",
      " [0.12 0.18 0.16 0.08 0.2  0.14 0.04 0.18 0.12 0.08 0.22 0.18 1.  ]]\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd']\n",
      "[[1.   0.1  0.06 0.06 0.1  0.06 0.02 0.08 0.1  0.02 0.06]\n",
      " [0.1  1.   0.22 0.04 0.22 0.08 0.06 0.3  0.24 0.1  0.06]\n",
      " [0.06 0.22 1.   0.04 0.18 0.14 0.06 0.14 0.1  0.08 0.06]\n",
      " [0.06 0.04 0.04 1.   0.02 0.12 0.12 0.   0.06 0.1  0.06]\n",
      " [0.1  0.22 0.18 0.02 1.   0.08 0.04 0.24 0.3  0.06 0.06]\n",
      " [0.06 0.08 0.14 0.12 0.08 1.   0.08 0.1  0.14 0.1  0.1 ]\n",
      " [0.02 0.06 0.06 0.12 0.04 0.08 1.   0.04 0.08 0.04 0.12]\n",
      " [0.08 0.3  0.14 0.   0.24 0.1  0.04 1.   0.28 0.06 0.02]\n",
      " [0.1  0.24 0.1  0.06 0.3  0.14 0.08 0.28 1.   0.04 0.08]\n",
      " [0.02 0.1  0.08 0.1  0.06 0.1  0.04 0.06 0.04 1.   0.06]\n",
      " [0.06 0.06 0.06 0.06 0.06 0.1  0.12 0.02 0.08 0.06 1.  ]]\n",
      "[0.06, 0.22, 1.0, 0.04, 0.18, 0.14, 0.06, 0.14, 0.1, 0.08, 0.06]\n",
      "<class 'list'>\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd', 'vie', 'zho']\n",
      "[[1.   0.06 0.08 0.04 0.14 0.1  0.02 0.1  0.1  0.02 0.04 0.1  0.04]\n",
      " [0.06 1.   0.14 0.1  0.14 0.12 0.02 0.12 0.18 0.06 0.08 0.04 0.02]\n",
      " [0.08 0.14 1.   0.08 0.24 0.04 0.02 0.2  0.1  0.04 0.04 0.14 0.14]\n",
      " [0.04 0.1  0.08 1.   0.08 0.02 0.04 0.12 0.1  0.08 0.08 0.04 0.06]\n",
      " [0.14 0.14 0.24 0.08 1.   0.06 0.06 0.26 0.1  0.02 0.08 0.16 0.16]\n",
      " [0.1  0.12 0.04 0.02 0.06 1.   0.04 0.06 0.06 0.08 0.1  0.06 0.02]\n",
      " [0.02 0.02 0.02 0.04 0.06 0.04 1.   0.06 0.   0.08 0.12 0.08 0.02]\n",
      " [0.1  0.12 0.2  0.12 0.26 0.06 0.06 1.   0.18 0.02 0.06 0.08 0.18]\n",
      " [0.1  0.18 0.1  0.1  0.1  0.06 0.   0.18 1.   0.14 0.08 0.1  0.08]\n",
      " [0.02 0.06 0.04 0.08 0.02 0.08 0.08 0.02 0.14 1.   0.1  0.08 0.08]\n",
      " [0.04 0.08 0.04 0.08 0.08 0.1  0.12 0.06 0.08 0.1  1.   0.08 0.08]\n",
      " [0.1  0.04 0.14 0.04 0.16 0.06 0.08 0.08 0.1  0.08 0.08 1.   0.06]\n",
      " [0.04 0.02 0.14 0.06 0.16 0.02 0.02 0.18 0.08 0.08 0.08 0.06 1.  ]]\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd']\n",
      "[[1.   0.02 0.04 0.04 0.04 0.02 0.04 0.1  0.06 0.08 0.06]\n",
      " [0.02 1.   0.06 0.04 0.12 0.04 0.02 0.06 0.06 0.06 0.04]\n",
      " [0.04 0.06 1.   0.02 0.1  0.   0.04 0.06 0.04 0.06 0.02]\n",
      " [0.04 0.04 0.02 1.   0.04 0.06 0.04 0.06 0.1  0.04 0.04]\n",
      " [0.04 0.12 0.1  0.04 1.   0.08 0.06 0.04 0.02 0.08 0.08]\n",
      " [0.02 0.04 0.   0.06 0.08 1.   0.02 0.06 0.04 0.02 0.04]\n",
      " [0.04 0.02 0.04 0.04 0.06 0.02 1.   0.1  0.02 0.1  0.04]\n",
      " [0.1  0.06 0.06 0.06 0.04 0.06 0.1  1.   0.1  0.04 0.06]\n",
      " [0.06 0.06 0.04 0.1  0.02 0.04 0.02 0.1  1.   0.06 0.  ]\n",
      " [0.08 0.06 0.06 0.04 0.08 0.02 0.1  0.04 0.06 1.   0.04]\n",
      " [0.06 0.04 0.02 0.04 0.08 0.04 0.04 0.06 0.   0.04 1.  ]]\n",
      "[0.04, 0.06, 1.0, 0.02, 0.1, 0.0, 0.04, 0.06, 0.04, 0.06, 0.02]\n",
      "<class 'list'>\n",
      "['ara', 'cat', 'eng', 'eus', 'fra', 'hin', 'mar', 'por', 'spa', 'tam', 'urd', 'vie', 'zho']\n",
      "[[1.   0.02 0.04 0.04 0.   0.02 0.   0.08 0.06 0.04 0.04 0.04 0.06]\n",
      " [0.02 1.   0.04 0.04 0.08 0.06 0.02 0.06 0.02 0.06 0.02 0.04 0.04]\n",
      " [0.04 0.04 1.   0.02 0.06 0.02 0.08 0.06 0.06 0.02 0.04 0.04 0.  ]\n",
      " [0.04 0.04 0.02 1.   0.04 0.06 0.04 0.02 0.06 0.06 0.   0.04 0.04]\n",
      " [0.   0.08 0.06 0.04 1.   0.04 0.12 0.06 0.06 0.02 0.04 0.02 0.1 ]\n",
      " [0.02 0.06 0.02 0.06 0.04 1.   0.06 0.06 0.08 0.1  0.08 0.02 0.06]\n",
      " [0.   0.02 0.08 0.04 0.12 0.06 1.   0.04 0.02 0.02 0.04 0.04 0.02]\n",
      " [0.08 0.06 0.06 0.02 0.06 0.06 0.04 1.   0.04 0.04 0.02 0.06 0.04]\n",
      " [0.06 0.02 0.06 0.06 0.06 0.08 0.02 0.04 1.   0.04 0.08 0.02 0.06]\n",
      " [0.04 0.06 0.02 0.06 0.02 0.1  0.02 0.04 0.04 1.   0.06 0.06 0.02]\n",
      " [0.04 0.02 0.04 0.   0.04 0.08 0.04 0.02 0.08 0.06 1.   0.04 0.02]\n",
      " [0.04 0.04 0.04 0.04 0.02 0.02 0.04 0.06 0.02 0.06 0.04 1.   0.02]\n",
      " [0.06 0.04 0.   0.04 0.1  0.06 0.02 0.04 0.06 0.02 0.02 0.02 1.  ]]\n",
      "defaultdict(<class 'dict'>, {'Number': {'best': 0.19745454545454547, '1000': 0.07127272727272727, '10000': 0.09345454545454544, '100000': 0.12836363636363635, '200000': 0.15672727272727272, '300000': 0.1556363636363636, '400000': 0.168, '500000': 0.09781818181818182, '600000': 0.051272727272727275}, 'POS': {'best': 0.1351282051282051, '1000': 0.05948717948717946, '10000': 0.07641025641025638, '100000': 0.0882051282051282, '200000': 0.09461538461538462, '300000': 0.12051282051282051, '400000': 0.13282051282051283, '500000': 0.0846153846153846, '600000': 0.04358974358974359}})\n",
      "defaultdict(<class 'dict'>, {'best': {'ar': 0.32, 'ca': 0.38, 'en': 1.0, 'eu': 0.16, 'fr': 0.26, 'hi': 0.2, 'mr': 0.06, 'pt': 0.32, 'es': 0.3, 'ta': 0.16, 'ur': 0.2}, '1000': {'ar': 0.08, 'ca': 0.12, 'en': 1.0, 'eu': 0.02, 'fr': 0.18, 'hi': 0.04, 'mr': 0.0, 'pt': 0.06, 'es': 0.08, 'ta': 0.06, 'ur': 0.02}, '10000': {'ar': 0.1, 'ca': 0.2, 'en': 1.0, 'eu': 0.02, 'fr': 0.22, 'hi': 0.1, 'mr': 0.04, 'pt': 0.16, 'es': 0.12, 'ta': 0.1, 'ur': 0.12}, '100000': {'ar': 0.16, 'ca': 0.2, 'en': 1.0, 'eu': 0.1, 'fr': 0.24, 'hi': 0.12, 'mr': 0.06, 'pt': 0.14, 'es': 0.16, 'ta': 0.12, 'ur': 0.14}, '200000': {'ar': 0.26, 'ca': 0.3, 'en': 1.0, 'eu': 0.16, 'fr': 0.14, 'hi': 0.12, 'mr': 0.04, 'pt': 0.24, 'es': 0.18, 'ta': 0.08, 'ur': 0.2}, '300000': {'ar': 0.22, 'ca': 0.24, 'en': 1.0, 'eu': 0.12, 'fr': 0.24, 'hi': 0.08, 'mr': 0.1, 'pt': 0.22, 'es': 0.24, 'ta': 0.1, 'ur': 0.18}, '400000': {'ar': 0.22, 'ca': 0.28, 'en': 1.0, 'eu': 0.08, 'fr': 0.28, 'hi': 0.14, 'mr': 0.04, 'pt': 0.32, 'es': 0.26, 'ta': 0.08, 'ur': 0.1}, '500000': {'ar': 0.06, 'ca': 0.22, 'en': 1.0, 'eu': 0.04, 'fr': 0.18, 'hi': 0.14, 'mr': 0.06, 'pt': 0.14, 'es': 0.1, 'ta': 0.08, 'ur': 0.06}, '600000': {'ar': 0.04, 'ca': 0.06, 'en': 1.0, 'eu': 0.02, 'fr': 0.1, 'hi': 0.0, 'mr': 0.04, 'pt': 0.06, 'es': 0.04, 'ta': 0.06, 'ur': 0.02}})\n"
     ]
    }
   ],
   "source": [
    "# ===========================read overlap ratios============================\n",
    "# Dict{attr: Dict{checkpoint: avg_overlap_rate}}\n",
    "avg_overlap_rates: Dict[str, Dict[str, float]] = defaultdict(dict)\n",
    "\n",
    "# Dict{ckpt: Dict{lang: overlap_rate_with_eng}}, this is to record the overlap rate with english only.\n",
    "number_ovlp_dict: Dict[str, Dict[str, float]] = defaultdict(dict)\n",
    "\n",
    "if layers is not None:\n",
    "    print(\"Loop over layers\")\n",
    "    for layer in layers:\n",
    "        embedding = model\n",
    "        experiment_name = f\"inter-layer-{layer}\"\n",
    "        if layer == 25:\n",
    "            experiment_name = \"last-layer\"\n",
    "        DEFAULT_RESULTS_FOLDER = f\"results/{embedding}/{experiment_name}\"\n",
    "\n",
    "        # print(listdir(DEFAULT_RESULTS_FOLDER))\n",
    "        RESULTS = []\n",
    "        rel_treebanks = []\n",
    "        for lang in listdir(DEFAULT_RESULTS_FOLDER):\n",
    "            if lang == 'UD_Chinese-CFL':\n",
    "                continue\n",
    "            rel_treebanks.append(lang)\n",
    "            for attr in listdir(join(DEFAULT_RESULTS_FOLDER, lang)):\n",
    "                RESULTS.append((lang, attr))\n",
    "                \n",
    "        # embedding, attribute, language\n",
    "\n",
    "        DEFAULT_FILE_FORMAT = join(DEFAULT_RESULTS_FOLDER, \"{lang}/{attribute}/loginfo.json\")\n",
    "\n",
    "        results_raw: List[Tuple[Dict[str, Any], List[int]]] = []\n",
    "\n",
    "        for l, a in RESULTS:  # noqa\n",
    "            if l in rel_treebanks:\n",
    "                with open(DEFAULT_FILE_FORMAT.format(lang=l, attribute=a), \"r\") as h:\n",
    "                    data = json.load(h)\n",
    "\n",
    "                results_raw.append(\n",
    "                    (\n",
    "                        { \"embedding\": embedding, \"attribute\": a,\n",
    "                        \"language\": convert_language_code(l) },\n",
    "                        [d[\"iteration_dimension\"] for d in data if \"iteration_dimension\" in d]\n",
    "                        if not random_baseline else random.sample(range(embedding_size), k=top_k)\n",
    "                    )\n",
    "            )\n",
    "        # Compute p values\n",
    "        num_permutations = 1000000\n",
    "        p_vals_cache_file = f\"{embedding}_{top_k}_{num_permutations}_pvals.pkl\"\n",
    "        if not os.path.exists(p_vals_cache_file):\n",
    "            # Compute p-values for different similarities\n",
    "            # if embedding in [\"bert-base-multilingual-cased\", \"xlm-roberta-base\"]:\n",
    "            #     dimensionality = 768\n",
    "            # elif embedding == \"xlm-roberta-large\":\n",
    "            #     dimensionality = 1024\n",
    "            # elif 'bloom' in embedding:\n",
    "            #     dimensionality = 1024\n",
    "            # else:\n",
    "            #     raise Exception(\"Embedding does not exist\")\n",
    "            #     dimensionality = 300\n",
    "            dimensionality = embedding_size\n",
    "\n",
    "            reference_order = random.sample(list(range(dimensionality)), dimensionality)\n",
    "            reference_top_k = reference_order[:top_k]\n",
    "            similarities = []\n",
    "\n",
    "            # for i in tqdm(range(num_permutations)):\n",
    "            #     permuted_top_k = random.sample(reference_order, top_k)\n",
    "            #     similarities.append(compute_overlap_coefficient(set(reference_top_k), set(permuted_top_k)))\n",
    "            #     pvals = {}\n",
    "\n",
    "            # for i in range(top_k + 1):\n",
    "            #     observed_hypothesis = i / top_k  # What is overlap score greater than or equal to?\n",
    "            #     permutations_match = [s for s in similarities if s >= observed_hypothesis]\n",
    "            #     pval = len(permutations_match) / num_permutations\n",
    "            #     print(f\"P-value when sim >= {observed_hypothesis} (overlap >= {i} dims): {pval:.5f}\")\n",
    "            #     pvals[i] = pval\n",
    "\n",
    "            with open(p_vals_cache_file, \"wb\") as h:\n",
    "                pickle.dump(pvals, h)\n",
    "        else:\n",
    "            with open(p_vals_cache_file, \"rb\") as h:\n",
    "                pvals = pickle.load(h)\n",
    "\n",
    "        for attr in attributes:\n",
    "            labels, (similarity_matrix, extra_data) = compute_similarity_for_attribute(\n",
    "                attr, results_raw, top_k)\n",
    "            \n",
    "            # get the average pairwise overlap:\n",
    "            print(len(labels))\n",
    "            print(similarity_matrix)\n",
    "            avg_overlap_rates[attr][layer] = np.average(similarity_matrix[np.triu_indices(len(labels), k = 1)])\n",
    "            \n",
    "\n",
    "            x_labels = labels\n",
    "            y_labels = labels\n",
    "\n",
    "            p_values_matrix = compute_pvalues(extra_data[\"overlap_num\"], pvals)\n",
    "            annotation_matrix = build_statistical_significance_matrix(\n",
    "                p_values_matrix, alpha=0.05, method=\"holm-bonferroni\", symmetry=True)\n",
    "    \n",
    "    for attr, overlap_rates in avg_overlap_rates.items():\n",
    "        overlap_rates = sorted(overlap_rates.items()) \n",
    "        print(overlap_rates)\n",
    "        x, y = zip(*overlap_rates)\n",
    "        \n",
    "        plt.plot(x, y, f'o-', label=attr)\n",
    "\n",
    "\n",
    "elif checkpoints is not None:\n",
    "    print(\"Loop over checkpoints\")\n",
    "    for checkpoint in checkpoints:\n",
    "        embedding = f\"{model}-intermediate-global_step{checkpoint}\"\n",
    "        if checkpoint == 'best':\n",
    "            embedding = model\n",
    "        DEFAULT_RESULTS_FOLDER = f\"results/{embedding}/{experiment_name}\"\n",
    "\n",
    "        # print(listdir(DEFAULT_RESULTS_FOLDER))\n",
    "        RESULTS = []\n",
    "        rel_treebanks = []\n",
    "        for lang in listdir(DEFAULT_RESULTS_FOLDER):\n",
    "            if lang == 'UD_Chinese-CFL':\n",
    "                continue\n",
    "            rel_treebanks.append(lang)\n",
    "            for attr in listdir(join(DEFAULT_RESULTS_FOLDER, lang)):\n",
    "                RESULTS.append((lang, attr))\n",
    "                \n",
    "        # embedding, attribute, language\n",
    "\n",
    "        DEFAULT_FILE_FORMAT = join(DEFAULT_RESULTS_FOLDER, \"{lang}/{attribute}/loginfo.json\")\n",
    "\n",
    "        results_raw: List[Tuple[Dict[str, Any], List[int]]] = []\n",
    "\n",
    "        for l, a in RESULTS:  # noqa\n",
    "            if l in rel_treebanks:\n",
    "                with open(DEFAULT_FILE_FORMAT.format(lang=l, attribute=a), \"r\") as h:\n",
    "                    data = json.load(h)\n",
    "\n",
    "                results_raw.append(\n",
    "                    (\n",
    "                        { \"embedding\": embedding, \"attribute\": a,\n",
    "                        \"language\": convert_language_code(l) },\n",
    "                        [d[\"iteration_dimension\"] for d in data if \"iteration_dimension\" in d]\n",
    "                        if not random_baseline else random.sample(range(embedding_size), k=top_k)\n",
    "                    )\n",
    "            )\n",
    "        # Compute p values\n",
    "        num_permutations = 1000000\n",
    "        p_vals_cache_file = f\"{embedding}_{top_k}_{num_permutations}_pvals.pkl\"\n",
    "        if not os.path.exists(p_vals_cache_file):\n",
    "            # Compute p-values for different similarities\n",
    "            # if embedding in [\"bert-base-multilingual-cased\", \"xlm-roberta-base\"]:\n",
    "            #     dimensionality = 768\n",
    "            # elif embedding == \"xlm-roberta-large\":\n",
    "            #     dimensionality = 1024\n",
    "            # elif 'bloom' in embedding:\n",
    "            #     dimensionality = 1024\n",
    "            # else:\n",
    "            #     raise Exception(\"Embedding does not exist\")\n",
    "            #     dimensionality = 300\n",
    "            dimensionality = embedding_size\n",
    "\n",
    "            reference_order = random.sample(list(range(dimensionality)), dimensionality)\n",
    "            reference_top_k = reference_order[:top_k]\n",
    "            similarities = []\n",
    "\n",
    "            for i in tqdm(range(num_permutations)):\n",
    "                permuted_top_k = random.sample(reference_order, top_k)\n",
    "                similarities.append(compute_overlap_coefficient(set(reference_top_k), set(permuted_top_k)))\n",
    "                pvals = {}\n",
    "\n",
    "            for i in range(top_k + 1):\n",
    "                observed_hypothesis = i / top_k  # What is overlap score greater than or equal to?\n",
    "                permutations_match = [s for s in similarities if s >= observed_hypothesis]\n",
    "                pval = len(permutations_match) / num_permutations\n",
    "                print(f\"P-value when sim >= {observed_hypothesis} (overlap >= {i} dims): {pval:.5f}\")\n",
    "                pvals[i] = pval\n",
    "\n",
    "            with open(p_vals_cache_file, \"wb\") as h:\n",
    "                pickle.dump(pvals, h)\n",
    "        else:\n",
    "            with open(p_vals_cache_file, \"rb\") as h:\n",
    "                pvals = pickle.load(h)\n",
    "\n",
    "        for attr in attributes:\n",
    "            labels, (similarity_matrix, extra_data) = compute_similarity_for_attribute(\n",
    "                attr, results_raw, top_k)\n",
    "            \n",
    "            # get the average pairwise overlap:\n",
    "            print(labels)\n",
    "            print(similarity_matrix)\n",
    "            if attr == 'Number':\n",
    "                ovlp_rate_with_eng = similarity_matrix[labels.index('eng')].tolist()\n",
    "                print(ovlp_rate_with_eng)\n",
    "                print(type(ovlp_rate_with_eng))\n",
    "                for lang, ovlp_rate in zip(labels, ovlp_rate_with_eng):\n",
    "                    langto2 = lang_code_dict_3to2[lang]\n",
    "                    number_ovlp_dict[checkpoint][langto2] = ovlp_rate\n",
    "\n",
    "            if checkpoint == 'best':\n",
    "                avg_overlap_rates[attr][checkpoint] = np.average(similarity_matrix[np.triu_indices(len(labels), k = 1)])\n",
    "            else:\n",
    "                avg_overlap_rates[attr][checkpoint] = np.average(similarity_matrix[np.triu_indices(len(labels), k = 1)])\n",
    "\n",
    "            x_labels = labels\n",
    "            y_labels = labels\n",
    "\n",
    "            p_values_matrix = compute_pvalues(extra_data[\"overlap_num\"], pvals)\n",
    "            annotation_matrix = build_statistical_significance_matrix(\n",
    "                p_values_matrix, alpha=0.05, method=\"holm-bonferroni\", symmetry=True)\n",
    "    \n",
    "    for attr, overlap_rates in avg_overlap_rates.items():\n",
    "        \n",
    "        if 'best' in overlap_rates.keys():\n",
    "            rate_for_best_checkpoint = [overlap_rates['best']]*8\n",
    "            # del overlap_rates['best']\n",
    "            # plt.plot(x, rate_for_best_checkpoint, f'-{color}', label=f'{model}-{attr}')\n",
    "            \n",
    "        # overlap_rates = sorted(overlap_rates.items()) \n",
    "        # x, y = zip(*overlap_rates)\n",
    "        \n",
    "        shape = shapes[attr]\n",
    "        \n",
    "        # ax2.plot(x, y, f'{shape}--', label=attr)      \n",
    "    \n",
    "else: \n",
    "    print(\"no x axises. please check.\")\n",
    "\n",
    "print(avg_overlap_rates)\n",
    "print(number_ovlp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(number_ovlp_dict)\n",
    "df.to_csv(f'csv_files/{model}_{experiment_name}_ovlp-rate_Number.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best': 0.1342079772079772, '1000': 0.04538909238909239, '10000': 0.04760805860805861, '50000': 0.06011884411884413, '100000': 0.0765050875050875, '150000': 0.08755718355718356, '200000': 0.09470288970288969, '250000': 0.10913268213268212, '300000': 0.11238298738298737}\n"
     ]
    }
   ],
   "source": [
    "ckpts_avg_overlap_rates = {}\n",
    "\n",
    "for ckpt in checkpoints:\n",
    "    ckpt_sum_rates = 0\n",
    "    for attr in attributes:\n",
    "        ckpt_sum_rates += avg_overlap_rates[attr][ckpt]\n",
    "    ckpts_avg_overlap_rates[ckpt] = ckpt_sum_rates/len(attributes)\n",
    "\n",
    "print(ckpts_avg_overlap_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"f1_rate_pairwise.txt\", 'a+') as f: \n",
    "    for ckpt in checkpoints:\n",
    "        for lang, f1_score in ckpt_lan_f1_dict[ckpt].items():\n",
    "            f.write('%s %s %s\\n' % (f1_score, pos_ovlp_dict[ckpt][lang_code_dict[lang]], ckpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"f1_rate_ckpts.txt\", 'a+') as f: \n",
    "#     for ckpt in checkpoints:\n",
    "#         f.write('%s %s %s\\n' % (avg_f1_dict[ckpt], ckpts_avg_overlap_rates[ckpt], ckpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.legend(loc='center left', bbox_to_anchor=(1.2, 0.5))\n",
    "# ax2.set_ylabel('overlap rates')\n",
    "# fig.gca().yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "# # fig.gca().yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "# if layers is not None:\n",
    "#     fig.xlabel(\"layer\")\n",
    "    \n",
    "# plt.style.use('seaborn-darkgrid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.tight_layout()\n",
    "# sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if layers is not None:\n",
    "#     plt.savefig(f'experiments/scatterplots/{model}/layers.pdf')\n",
    "# elif checkpoints is not None:\n",
    "#     plt.savefig(f'experiments/scatterplots/{model}/checkpoints_{experiment_name}.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilingual-typology-probing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed44db9dbf3c575ec3ddf9da9744b6e2502eab3ed89ccbe6b1ade08a3a1a68bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
